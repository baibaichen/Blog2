# Velox: Metaâ€™s Unified Execution Engine

## ABSTRACT
> The ad-hoc development of new specialized computation engines targeted to very specific data workloads has created a siloed data landscape. Commonly, these engines share little to nothing with each other and are hard to maintain, evolve, and optimize, and ultimately provide an inconsistent experience to data users. In order to address these issues, Meta has created Velox, a novel open source C++ database acceleration library. Velox provides reusable, extensible, high-performance, and dialect-agnostic data processing components for building execution engines, and enhancing data management systems. The library heavily relies on vectorization and adaptivity, and is designed from the ground up to support efficient computation over complex data types due to their ubiquity in modern workloads. Velox is currently integrated or being integrated with more than a dozen data systems at Meta, including analytical query engines such as Presto and Spark, stream processing platforms, message buses and data warehouse ingestion infrastructure, machine learning systems for feature engineering and data preprocessing (PyTorch), and more. It provides benefits in terms of (a) efficiency wins by democratizing optimizations previously only found in individual engines, (b) increased consistency for data users, and (c) engineering efficiency by promoting reusability.

é’ˆå¯¹éå¸¸å…·ä½“çš„æ•°æ®å·¥ä½œè´Ÿè½½çš„æ–°ä¸“ä¸šè®¡ç®—å¼•æ“çš„ä¸´æ—¶å¼€å‘åˆ›é€ äº†ä¸€ä¸ªå­¤ç«‹çš„æ•°æ®ç¯å¢ƒã€‚é€šå¸¸ï¼Œè¿™äº›å¼•æ“å½¼æ­¤å‡ ä¹æ²¡æœ‰å…±äº«ï¼Œå¹¶ä¸”éš¾ä»¥ç»´æŠ¤ã€å‘å±•å’Œä¼˜åŒ–ï¼Œå¹¶æœ€ç»ˆä¸ºæ•°æ®ç”¨æˆ·æä¾›ä¸ä¸€è‡´çš„ä½“éªŒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒMeta åˆ›å»ºäº† Veloxï¼Œä¸€ä¸ªæ–°é¢–çš„å¼€æº C++ æ•°æ®åº“åŠ é€Ÿåº“ã€‚Velox æä¾›å¯é‡ç”¨ã€å¯æ‰©å±•ã€é«˜æ€§èƒ½å’Œæ–¹è¨€ä¸å¯çŸ¥çš„æ•°æ®å¤„ç†ç»„ä»¶ï¼Œç”¨äºæ„å»ºæ‰§è¡Œå¼•æ“å’Œå¢å¼ºæ•°æ®ç®¡ç†ç³»ç»Ÿã€‚è¯¥åº“ä¸¥é‡ä¾èµ–çŸ¢é‡åŒ–å’Œè‡ªé€‚åº”æ€§ï¼Œå¹¶ä¸”ä»å¤´å¼€å§‹è®¾è®¡ä»¥æ”¯æŒå¯¹å¤æ‚æ•°æ®ç±»å‹çš„é«˜æ•ˆè®¡ç®—ï¼Œå› ä¸ºå®ƒä»¬åœ¨ç°ä»£å·¥ä½œè´Ÿè½½ä¸­æ— å¤„ä¸åœ¨ã€‚Velox ç›®å‰æ­£åœ¨ä¸ Meta çš„åå‡ ä¸ªæ•°æ®ç³»ç»Ÿé›†æˆï¼ŒåŒ…æ‹¬ Presto å’Œ Spark ç­‰åˆ†ææŸ¥è¯¢å¼•æ“ã€æµå¤„ç†å¹³å°ã€æ¶ˆæ¯æ€»çº¿å’Œæ•°æ®ä»“åº“æ‘„å–åŸºç¡€è®¾æ–½ã€ç”¨äºç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é¢„å¤„ç†çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼ˆPyTorchï¼‰ç­‰ã€‚å®ƒåœ¨ä»¥ä¸‹æ–¹é¢æä¾›äº†å¥½å¤„ï¼š(a) å¤§ä¼—åŒ–ä»¥å‰ä»…åœ¨å•ä¸ªå¼•æ“ä¸­å‘ç°çš„ä¼˜åŒ–ï¼Œä»¥æ­¤æ¥æé«˜æ•ˆç‡ï¼Œ(b) æé«˜æ•°æ®ç”¨æˆ·çš„ä¸€è‡´æ€§ï¼Œä»¥åŠ (c) é€šè¿‡æé«˜å¯é‡ç”¨æ€§æ¥æé«˜å·¥ç¨‹æ•ˆç‡ã€‚

## 1 INTRODUCTION
> The increasing workload diversity in modern data use cases coupled with exponential dataset growth have led to the proliferation of specialized query and computation engines, each targeted to a very specific type of workload. Data processing requirements have grown from simple transaction processing and analytics (both batch and interactive), to ETL and bulk data movement, to realtime stream processing, to log and timeseries processing for monitoring use cases, to more recently, a plethora of artificial intelligence (AI) and machine learning (ML) use cases including data preprocessing and feature engineering.
>
> This evolution has created a siloed data ecosystem composed of dozens of specialized engines that are built using different frameworks and libraries and share little to nothing with each other, are written in different languages, and are maintained by different engineering teams. Moreover, evolving and optimizing these engines as hardware and use cases evolve, is cost prohibitive if done on a per-engine basis. For example, extending every engine to better leverage novel hardware advancements, like cache-coherent accelerators and NVRAM, supporting features like Tensor data types for ML workloads, and leveraging future innovations made by the research community are impractical and invariably lead to engines with disparate sets of optimizations and features. More importantly, this fragmentation ultimately impacts the productivity of data users, who are commonly required to interact with several different engines to finish a particular task. The available data types, functions, and aggregates vary across these systems, and the behavior of those functions, null handling, and casting can be vastly inconsistent across engines. For instance, an informal survey conducted at Meta identified at least 12 different implementations of the simple string manipulation function ğ‘ ğ‘¢ğ‘ğ‘ ğ‘¡ğ‘Ÿ (), presenting different parameter semantics (0- vs. 1-based indices), null handling, and exception behavior.
>
> Although specialized engines, by definition, provide specialized behavior that justifies their existence, the main differences are commonly in the language frontend (SQL, dataframes, and other DSLs), the optimizer, the way tasks are distributed among worker nodes (also referred to as the runtime), and the IO layer. The execution engines at the core of these systems are all rather similar. All engines need a type system to represent scalar and complex data types, an in memory representation of these (often columnar) datasets, an expression evaluation system, operators (such as joins, aggregation, and sort), in addition to storage and network serialization, encoding formats, and resource management primitives.
>
> In order to address these issues, Meta has developed Velox, a novel C++ database acceleration library that provides reusable, extensible, and high-performance data processing components which can be used to build, enhance, or replace execution engines in existing data management systems. Velox is designed from the ground up to efficiently support complex types due to their ubiquity in modernworkloads, and heavily relies on vectorization [4] and adaptivity. Velox components are language, dialect, and engine-agnostic, and provide many extensibility points where developers can specialize the library behavior and match a particular engineâ€™s requirements. In common usage scenarios, Velox takes a fully optimized query plan as input and performs the described computation using the resources available in the local node. As such, Velox does not provide a SQL parser, a dataframe layer, other DSLs, or a global query optimizer, and it is usually not meant to be used directly by data users.
>
> Veloxâ€™s value proposition is three-fold:
>
> - **Efficiency**: Velox democratizes runtime optimizations previously only implemented in individual engines, such as fully leveraging SIMD, lazy evaluation, adaptive predicate re-ordering and pushdown, common subexpression elimination, execution over encoded data, code generation, and more.
> - **Consistency**: by leveraging the same execution library, compute engines can expose the exact same data types and scalar/aggregate function packages, and thus provide a more consistent experience to data users due to their unified behavior.
> - **Engineering Efficiency**: all features and runtime optimizations available in Velox are developed and maintained once, thus reducing engineering duplication and promoting reusability.
>
> Velox is under active development and is already integrated or being integrated with more than a dozen data systems at Meta (and beyond), such as Presto, Spark, PyTorch, XStream (stream processing), F3 (feature engineering), FBETL (data ingestion), XSQL (distributed transaction processing), Scribe (message bus infrastructure), Saber (high QPS external serving), and others.
>
> We believe Velox to be a major step towards making data systems more modular and interoperable, with the ultimate goal of providing a more responsible implementation of the â€œone size does not fit allâ€ mantra. Considering the potential impact in the community, Velox is open-source1 and backed by a fast growing community, including members such as Ahana, Intel, Voltron Data, and many other major technology companies and academic partners. Lastly, we also believe that, strategically, Velox will allow Meta to partner with hardware vendors and proactively prepare our data systems for tomorrowâ€™s hardware, in addition to streamlining collaborations with researchers and research labs.
>
> In this paper, we make the following contributions:
>
> - We detail the Velox library, its components, extensibility points, and main optimizations.
> - We describe how Velox is being integrated with compute engines targeted at very diverse workloads, such as batch and interactive analytics, stream processing, data warehouse ingestion, ML, and more.
> - We highlight how Velox is transforming Metaâ€™s data landscape, which has traditionally been composed of siloed and specialized engines providing inconsistent semantics for data users.
> - We present micro-benchmarks to motivate Veloxâ€™s main optimizations, in addition to experimental results with Veloxâ€™s integration with Presto.
> - We discuss lessons learned during this journey, future work, and open questions with the hope of motivating further research and fostering collaboration.

ç°ä»£æ•°æ®ç”¨ä¾‹ä¸­å·¥ä½œè´Ÿè½½çš„å¤šæ ·æ€§ä¸æ–­å¢åŠ ï¼ŒåŠ ä¸Šæ•°æ®é›†å‘ˆæŒ‡æ•°çº§å¢é•¿ï¼Œå¯¼è‡´ä¸“ç”¨æŸ¥è¯¢å’Œè®¡ç®—å¼•æ“æ¿€å¢ï¼Œæ¯ä¸ªå¼•æ“éƒ½é’ˆå¯¹ä¸€ç§éå¸¸ç‰¹å®šç±»å‹çš„å·¥ä½œè´Ÿè½½ã€‚æ•°æ®å¤„ç†éœ€æ±‚å·²ç»ä»ç®€å•çš„äº‹åŠ¡å¤„ç†å’Œåˆ†æï¼ˆæ‰¹å¤„ç†å’Œäº¤äº’å¼ï¼‰å‘å±•åˆ° ETL å’Œæ‰¹é‡æ•°æ®ç§»åŠ¨ï¼Œå†åˆ°å®æ—¶æµå¤„ç†ï¼Œå†åˆ°ç”¨äºç›‘æ§ç”¨ä¾‹çš„æ—¥å¿—å’Œæ—¶é—´åºåˆ—å¤„ç†ï¼Œå†åˆ°æœ€è¿‘å¤§é‡çš„äººå·¥æ™ºèƒ½ï¼ˆ AI) å’Œæœºå™¨å­¦ä¹  (ML) ç”¨ä¾‹ï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ã€‚

è¿™ç§æ¼”å˜åˆ›é€ äº†ä¸€ä¸ªç”±æ•°åä¸ªä¸“ç”¨å¼•æ“ç»„æˆçš„å­¤ç«‹æ•°æ®ç”Ÿæ€ç³»ç»Ÿï¼Œè¿™äº›å¼•æ“ä½¿ç”¨ä¸åŒçš„æ¡†æ¶å’Œåº“æ„å»ºï¼Œå½¼æ­¤ä¹‹é—´å‡ ä¹æ²¡æœ‰å…±äº«ï¼Œç”¨ä¸åŒçš„è¯­è¨€ç¼–å†™ï¼Œå¹¶ç”±ä¸åŒçš„å·¥ç¨‹å›¢é˜Ÿç»´æŠ¤ã€‚æ­¤å¤–ï¼Œéšç€ç¡¬ä»¶å’Œç”¨ä¾‹çš„å‘å±•ï¼Œå¯¹è¿™äº›å¼•æ“è¿›è¡Œæ”¹è¿›å’Œä¼˜åŒ–ï¼Œå¦‚æœä»¥æ¯ä¸ªå¼•æ“ä¸ºåŸºç¡€ï¼Œåˆ™æˆæœ¬è¿‡é«˜ã€‚ä¾‹å¦‚ï¼Œæ‰©å±•æ¯ä¸€ä¸ªå¼•æ“ä»¥æ›´å¥½åœ°åˆ©ç”¨æ–°çš„ç¡¬ä»¶è¿›æ­¥ï¼Œå¦‚ç¼“å­˜ä¸€è‡´åŠ é€Ÿå™¨å’Œ NVRAMï¼Œæ”¯æŒç”¨äº ML å·¥ä½œè´Ÿè½½çš„ Tensor æ•°æ®ç±»å‹ç­‰åŠŸèƒ½ï¼Œå¹¶åˆ©ç”¨ç ”ç©¶ç•Œæœªæ¥çš„åˆ›æ–°ï¼Œè¿™ä¸åˆ‡å®é™…ï¼Œå¹¶ä¸”æ€»æ˜¯å¯¼è‡´å¼•æ“å…·æœ‰ä¸åŒçš„ä¼˜åŒ–å’ŒåŠŸèƒ½é›†ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™ç§ç¢ç‰‡åŒ–æœ€ç»ˆä¼šå½±å“æ•°æ®ç”¨æˆ·çš„ç”Ÿäº§åŠ›ï¼Œä»–ä»¬é€šå¸¸éœ€è¦ä¸å‡ ä¸ªä¸åŒçš„å¼•æ“äº¤äº’æ‰èƒ½å®Œæˆç‰¹å®šä»»åŠ¡ã€‚åœ¨è¿™äº›ç³»ç»Ÿä¸­ï¼Œå¯ç”¨çš„æ•°æ®ç±»å‹ã€å‡½æ•°å’Œèšåˆå„ä¸ç›¸åŒï¼Œè¿™äº›å‡½æ•°çš„è¡Œä¸ºã€ç©ºå¤„ç†å’Œè½¬æ¢åœ¨ä¸åŒçš„å¼•æ“ä¸­å¯èƒ½æä¸ä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œåœ¨ Meta è¿›è¡Œçš„ä¸€é¡¹éæ­£å¼è°ƒæŸ¥å‘ç°ï¼Œç®€å•å­—ç¬¦ä¸²æ“ä½œå‡½æ•° `ğ‘ ğ‘¢ğ‘ğ‘ ğ‘¡r()` è‡³å°‘æœ‰ 12 ç§ä¸åŒå®ç°ï¼Œæœ‰ä¸åŒçš„å‚æ•°è¯­ä¹‰ï¼ˆåŸºäº 0 æˆ–åŸºäº 1 çš„ç´¢å¼•ï¼‰ã€ç©ºå€¼å¤„ç†å’Œå¤„ç†å¼‚å¸¸çš„è¡Œä¸ºã€‚

å°½ç®¡æ ¹æ®å®šä¹‰ï¼Œä¸“ç”¨å¼•æ“æä¾›äº†è¯æ˜å…¶å­˜åœ¨åˆç†æ€§çš„ä¸“ç”¨è¡Œä¸ºï¼Œä½†ä¸»è¦åŒºåˆ«é€šå¸¸åœ¨äºè¯­è¨€å‰ç«¯ï¼ˆSQLã€Dataframe å’Œå…¶ä»– DSLï¼‰ã€ä¼˜åŒ–å™¨ã€ä»»åŠ¡åœ¨å·¥ä½œèŠ‚ç‚¹ä¹‹é—´çš„åˆ†å¸ƒæ–¹å¼ï¼ˆä¹Ÿç§°ä¸º è¿è¡Œæ—¶ï¼‰å’Œ IO å±‚ã€‚è¿™äº›ç³»ç»Ÿæ ¸å¿ƒçš„æ‰§è¡Œå¼•æ“éƒ½éå¸¸ç›¸ä¼¼ã€‚é™¤äº†å­˜å‚¨å’Œç½‘ç»œåºåˆ—åŒ–ã€<u>==ç¼–ç æ ¼å¼==</u>å’Œèµ„æºç®¡ç†åŸè¯­ä¹‹å¤–ï¼Œæ‰€æœ‰å¼•æ“éƒ½éœ€è¦ä¸€ä¸ªç±»å‹ç³»ç»Ÿæ¥è¡¨ç¤ºæ ‡é‡å’Œå¤æ‚æ•°æ®ç±»å‹ã€è¿™äº›æ•°æ®é›†çš„å†…å­˜è¡¨ç¤ºï¼ˆé€šå¸¸æ˜¯åˆ—å¼ï¼‰ã€è¡¨è¾¾å¼è¯„ä¼°ç³»ç»Ÿã€è¿ç®—ç¬¦ï¼ˆä¾‹å¦‚è¿æ¥ã€èšåˆå’Œæ’åºï¼‰ã€‚

ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼ŒMeta å¼€å‘äº† Veloxï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ C++ æ•°æ®åº“åŠ é€Ÿåº“ï¼Œå®ƒæä¾›å¯é‡ç”¨ã€å¯æ‰©å±•å’Œé«˜æ€§èƒ½çš„æ•°æ®å¤„ç†ç»„ä»¶ï¼Œå¯ç”¨äºæ„å»ºã€å¢å¼ºæˆ–æ›¿æ¢ç°æœ‰æ•°æ®ç®¡ç†ç³»ç»Ÿä¸­çš„æ‰§è¡Œå¼•æ“ã€‚ Velox çš„è®¾è®¡åˆè¡·æ˜¯ä¸ºäº†æœ‰æ•ˆæ”¯æŒå¤æ‚ç±»å‹ï¼Œå› ä¸ºå®ƒä»¬åœ¨ç°ä»£å·¥ä½œè´Ÿè½½ä¸­æ— å¤„ä¸åœ¨ï¼Œå¹¶ä¸”åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå‘é‡åŒ– [4] å’Œè‡ªé€‚åº”æ€§ã€‚ Velox ç»„ä»¶ä¸è¯­è¨€ã€æ–¹è¨€å’Œå¼•æ“æ— å…³ï¼Œå¹¶æä¾›è®¸å¤šå¯æ‰©å±•ç‚¹ï¼Œå¼€å‘äººå‘˜å¯ä»¥åœ¨å…¶ä¸­ä¸“é—¨åŒ–åº“è¡Œä¸ºå¹¶æ»¡è¶³ç‰¹å®šå¼•æ“çš„è¦æ±‚ã€‚ åœ¨å¸¸è§çš„ä½¿ç”¨åœºæ™¯ä¸­ï¼ŒVelox å°†å®Œå…¨ä¼˜åŒ–çš„æŸ¥è¯¢è®¡åˆ’ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä½¿ç”¨æœ¬åœ°èŠ‚ç‚¹ä¸­å¯ç”¨çš„èµ„æºæ‰§è¡Œæ‰€æè¿°çš„è®¡ç®—ã€‚ å› æ­¤ï¼ŒVelox ä¸æä¾› SQL è§£æå™¨ã€DataFrameã€å…¶ä»– DSL æˆ–å…¨å±€æŸ¥è¯¢ä¼˜åŒ–å™¨ï¼Œé€šå¸¸æ•°æ®ç”¨æˆ·ä¸ä¼šç›´æ¥ä½¿ç”¨å®ƒã€‚

Velox çš„<u>==ä»·å€¼ä¸»å¼ ==</u>æœ‰ä¸‰æ–¹é¢ï¼š

- **æ•ˆç‡**ï¼šVelox å¤§ä¼—åŒ–äº†ä»¥å‰åªåœ¨å•ä¸ªå¼•æ“ä¸­å®ç°çš„è¿è¡Œæ—¶ä¼˜åŒ–ï¼Œä¾‹å¦‚å……åˆ†åˆ©ç”¨ SIMDï¼Œå»¶è¿Ÿè®¡ç®—ï¼Œè‡ªé€‚åº”è°“è¯é‡æ’å’Œä¸‹æ¨ï¼Œå…¬å…±å­è¡¨è¾¾å¼æ¶ˆé™¤ï¼Œ<u>==ç¼–ç æ•°æ®æ‰§è¡Œ==</u>ï¼Œä»£ç ç”Ÿæˆç­‰ã€‚
- **ä¸€è‡´æ€§**ï¼šé€šè¿‡åˆ©ç”¨ç›¸åŒçš„æ‰§è¡Œåº“ï¼Œè®¡ç®—å¼•æ“å¯ä»¥å…¬å¼€å®Œå…¨ç›¸åŒçš„æ•°æ®ç±»å‹å’Œæ ‡é‡/èšåˆå‡½æ•°åŒ…ï¼Œä»è€Œä¸ºæ•°æ®ç”¨æˆ·æä¾›æ›´åŠ ä¸€è‡´çš„ä½“éªŒï¼Œå› ä¸ºå®ƒä»¬çš„è¡Œä¸ºæ˜¯ç»Ÿä¸€çš„ã€‚
- **å·¥ç¨‹æ•ˆç‡**ï¼šVelox ä¸­å¯ç”¨çš„æ‰€æœ‰åŠŸèƒ½å’Œè¿è¡Œæ—¶ä¼˜åŒ–éƒ½æ˜¯ä¸€æ¬¡å¼€å‘å’Œç»´æŠ¤ï¼Œä»è€Œå‡å°‘äº†é‡å¤å·¥åšï¼Œæé«˜å¯é‡ç”¨æ€§ã€‚

Velox æ­£åœ¨ç§¯æå¼€å‘ä¸­ï¼Œå·²ç»æˆ–æ­£åœ¨ä¸ Metaï¼ˆåŠå…¶ä»–ï¼‰çš„åå¤šä¸ªæ•°æ®ç³»ç»Ÿé›†æˆï¼Œå¦‚ Prestoã€Sparkã€PyTorchã€XStreamï¼ˆæµå¤„ç†ï¼‰ã€F3(ç‰¹å¾å·¥ç¨‹)ã€FBETLï¼ˆæ•°æ®è¾“å…¥ï¼‰ã€XSQLï¼ˆåˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†ï¼‰ã€Scribeï¼ˆæ¶ˆæ¯æ€»çº¿åŸºç¡€è®¾æ–½ï¼‰ã€Saberï¼ˆé«˜ QPS å¤–éƒ¨æœåŠ¡ï¼‰ç­‰ã€‚

æˆ‘ä»¬ç›¸ä¿¡ Velox æ˜¯æœç€ä½¿æ•°æ®ç³»ç»Ÿæ›´åŠ æ¨¡å—åŒ–å’Œå¯äº’æ“ä½œçš„æ–¹å‘è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ï¼Œ**å…¶æœ€ç»ˆç›®æ ‡æ˜¯æä¾›æ›´è´Ÿè´£ä»»çš„â€œä¸€åˆ€åˆ‡â€æ–¹æ¡ˆ**ã€‚è€ƒè™‘åˆ°å¯¹ç¤¾åŒºçš„æ½œåœ¨å½±å“ï¼ŒVelox æ˜¯å¼€æºçš„ï¼Œå¹¶å¾—åˆ°äº†ä¸€ä¸ªå¿«é€Ÿå¢é•¿çš„ç¤¾åŒºçš„æ”¯æŒï¼Œå…¶ä¸­åŒ…æ‹¬ Ahanaã€Intelã€Voltron Data ä»¥åŠè®¸å¤šå…¶ä»–ä¸»è¦æŠ€æœ¯å…¬å¸å’Œå­¦æœ¯åˆä½œä¼™ä¼´ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜ç›¸ä¿¡ï¼Œä»æˆ˜ç•¥ä¸Šè®²ï¼Œé™¤äº†ç®€åŒ–ä¸ç ”ç©¶äººå‘˜å’Œç ”ç©¶å®éªŒå®¤çš„åˆä½œå¤–ï¼ŒVelox è¿˜å°†å…è®¸ Meta ä¸ç¡¬ä»¶ä¾›åº”å•†åˆä½œï¼Œå¹¶ä¸»åŠ¨ä¸ºæœªæ¥çš„ç¡¬ä»¶å‡†å¤‡æˆ‘ä»¬çš„æ•°æ®ç³»ç»Ÿã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åšå‡ºä»¥ä¸‹è´¡çŒ®ï¼š

- æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº† Velox åº“ã€å…¶ç»„ä»¶ã€æ‰©å±•ç‚¹å’Œä¸»è¦ä¼˜åŒ–ã€‚

- æˆ‘ä»¬æè¿°äº† Velox å¦‚ä½•ä¸<u>é’ˆå¯¹å„ç§å·¥ä½œè´Ÿè½½çš„</u>è®¡ç®—å¼•æ“é›†æˆï¼Œä¾‹å¦‚æ‰¹å¤„ç†å’Œäº¤äº’å¼åˆ†æã€æµå¤„ç†ã€æ•°æ®ä»“åº“æ‘„å–ã€ML ç­‰ã€‚
- æˆ‘ä»¬é‡ç‚¹ä»‹ç»äº† Velox å¦‚ä½•æ”¹å˜ Meta çš„æ•°æ®ç¯å¢ƒï¼Œä¼ ç»Ÿä¸Š Meta çš„æ•°æ®ç¯å¢ƒç”±å­¤ç«‹çš„ä¸“ç”¨å¼•æ“ç»„æˆï¼Œä¸ºæ•°æ®ç”¨æˆ·æä¾›ä¸ä¸€è‡´çš„è¯­ä¹‰ã€‚
- é™¤äº† Velox ä¸ Presto é›†æˆçš„å®éªŒç»“æœå¤–ï¼Œ<u>==æˆ‘ä»¬è¿˜æä¾›äº†å¾®åŸºå‡†æ¥æ¨åŠ¨ Velox çš„ä¸»è¦ä¼˜åŒ–==</u>ã€‚
- æˆ‘ä»¬è®¨è®ºåœ¨è¿™æ¬¡æ—…ç¨‹ä¸­å¸å–çš„æ•™è®­ã€æœªæ¥çš„å·¥ä½œå’Œæœªè§£å†³çš„é—®é¢˜ï¼Œä»¥æœŸæ¿€å‘è¿›ä¸€æ­¥çš„ç ”ç©¶å’Œä¿ƒè¿›åˆä½œã€‚

## 2 LIBRARY OVERVIEW

Velox is an open source C++ database acceleration library that provides high-performance, reusable, and extensible data processing components, which can be used to accelerate, extend, and enhance data computation engines. Velox does not provide a language frontend, such as a SQL parser, dataframe layer, or other DSLs; instead, it expects a fully optimized query plan as input describing the computation to be performed, and executes it locally using the resources available in the local host. 

Furthermore, Velox does not provide a global query optimizer, but at execution time leverages numerous adaptivity techniques, such as filter and conjunct reordering, dynamic filter pushdown, and adaptive column prefetching. In other words, the components provided by Velox usually sit on the data-plane, while individual engines are responsible for providing the control-plane. The highlevel components provided by Velox are:

- **Type**: a generic type system that allows users to represent scalar, complex, and nested data types, including structs, maps, arrays, tensors, and more.
- **Vector**: an Arrow-compatible2 columnar memory layout module, supporting multiple encodings, such as Flat, Dictionary, Constant, Sequence/RLE, and Bias (frame of reference), in addition to a lazy materialization pattern and support for out-of-order result buffer population.
- **Expression Eval**: a fully vectorized expression evaluation engine built based on Vector-encoded data, leveraging techniques such as common subexpression elimination, constant folding, efficient null propagation, encoding-aware evaluation, and dictionary memoization.
- **Functions**: APIs that can be used by developers to build custom functions, providing a simple (row-by-row) and vectorized (batch-by-batch) interface for scalar functions, and APIs for aggregate functions. Function packages compatible with popular SQL dialects are also provided by the library (currently, for Presto and Spark).
- **Operators**: implementation of common data processing operators such as TableScan, Project, Filter, Aggregation, Exchange/ Merge, OrderBy, HashJoin, MergeJoin, Unnest, and more.
- **I/O**: a generic connector interface that allows for pluggable file format encoders/decoders and storage adapters. Support for popular formats such as ORC and Parquet, and S3 and HDFS storage systems are included in the library.
- **Serializers**: a serialization interface targeting network communication where different wire protocols can be implemented, supporting PrestoPage and Sparkâ€™s UnsafeRow formats.
- **Resource Management**: a collection of primitives for handling computational resources, such as memory arenas and buffer management, tasks, drivers, and thread pools for CPU and thread execution, spilling, and caching.

Engines integrating with Velox can choose which components to use based on the functionality required. For instance, engines with simple data representation and serialization requirements can leverage Type, Vector, and Serializer only, while a complete SQL analytical query engine would require the full extent of operators and resource management primitives available.

In addition to being modular, Velox also provides extensibility APIs that can be used to customize the library. Developers can use these APIs to add plugins to support custom data types, scalar and aggregate functions, engine-specific operators, new serialization formats, file encodings, and storage adapters. The decision about whether a particular plugin will be provided as part of the main library or not is based on its genericity: if it is used by multiple engines (e.g. Parquet and ORC file encoders, and common operators such as Aggregate, OrderBy, and HashJoin), they are included in the main library; otherwise, they are provided as part of the clientâ€™s engine codebase (e.g. ML-specific functions and stream processing operators).
