#  Evolving Databases for New-Gen Big Data Applications

## 概要

大规模实时分析应用程序（实时库存/定价、为您提供推荐的移动应用程序、欺诈检测、风险分析等）的日益流行，**着重要求**了分布式数据管理系统能够处理快速交易的同时，也能进行分析。然而，高效处理事务性和分析性请求，在系统中有不同的优化决策和体系架构。本文介绍了 **Wildfire** 系统，该系统针对**混合事务和分析处理** (HTAP)。 Wildfire 利用 Spark 生态系统处理大规模数据，可应对不同类型的复杂分析请求，利用<u>列式数据</u>实现快速事务和并发分析。

## 1. 简介

由于<u>==**它们的**==</u>演变方式，关系 DBMS 一直是事务能力最强的系统，可确保经典的 *ACID* 属性。早期文献定义了如何实现并发事务的**严格串行化和隔离，**以及实现分布式事务一致性提交的**两阶段提交协议**。典型的事务是在点查询中访问个别行，任何列上的索引（而不仅仅是主键）有助于完成这样的工作。但是传统的 DBMS 也为更复杂的分析查询开发了重要的技术，特别是声明式的**结构化查询语言** (SQL) 及其强大的优化，以及在多节点上并行执行，以加速长时运行的查询。最近，DBMS 利用多线程并行、压缩、大内存，尤其是列存的复杂利用，大大加快了分析查询的性能[[22](#_bookmark29), [26](#_bookmark33), [30]( #_bookmark37), [33](#_bookmark40)]。

尽管如此，DBMS 也有其弱点。 DBMS 是一个封闭系统，独占其数据，必须将其加载到其专有格式中，这会减慢需要大量数据应用程序（如机器学习）的检索速度。数据复制通常作为出现灾难后，事后恢复而设计，可用性通常只限于那些与单个副本具有物理连接的节点，并且取决于两阶段提交的协调器是否启动。通常，CAP 定理指出严格的一致性使得可用性非常困难 [23]。 超过数百个DBMS 节点的横向扩展很少见，而且弹性有限，因为数据被**预先分配并存储在预先确定的（一组）节点上**。

这些弱点在很大程度上推动了大数据平台的近期发展，例如 Hadoop [5] 和现在的 Spark[11]，这些平台的设计几乎完全是为了在极其庞大和多样化的数据集上，经济高效地执行复杂和长时运行的分析（如机器学习）。这些系统促进了更加开放的环境，包括功能和事实上的标准数据格式（例如 Parquet），允许任何**功能**能轻松访问任何数据，而无需通过集中的服务。通过默认情况下（通常异步地）定期复制数据（例如，使用最终一致性语义），这些系统从一开始就内置高可用性、可扩展性和弹性。

然而，大数据平台有其自身的缺点。事务（尤其是就地更新）和点查询在 Spark 中基本上被忽略，从而将数据的**==摄取==**降级到更简单的键值存储，例如 Cassandra[4] 和 Aerospike [1]。其中一些存储能提供较高的<u>**摄取率**</u>，可以满足新的**物联网 (IoT) 应用程序**<u>收集数据</u>时所需的性能，但为了实现这一点，这些存储放宽了隔离级别，并在独立节点上接受了较弱的<u>最终一致性</u>。 同时还只索引主键，将<u>点查询限制</u>为那些指定该键的查询。最后，它们只有受限的或没有 SQL 功能，这些功能几乎是事后才想到的（例如，Hive [34]），查询优化器很。

本文认为，大数据世界需要事务。我们展示了 Wildfire 的初始原型设计，可将 ACID 事务（尽管具有较弱的快照隔离形式）引入 Spark 开放的分析世界。Wildfire 利用 Spark 通过以下方式执行分析：(1) 对所有数据使用**非专有存储格式 (Parquet)**，对任何 `reader` 开放； (2) 使用和扩展 Spark API 和 Catalyst 优化器用于SQL 查询； (3) 自动复制数据以实现高可用性、横向扩展性能和弹性（创建 AP 系统）。 Wildfire 使用传统 DBMS 世界中的关键功能增强 Spark，包括： (1) 具有快照隔离的 ACID 事务，使最新提交的数据立即可用于分析查询； (2) 能够索引任何列以进行快速点查询； (3)  利用最新进展，加速分析查询，提高好几个数量级，包括**动态压缩**、缓存感知处理、**==概要==**的自动创建和利用、（某种形式的）列式存储和多线程并行性; (4) 企业级 SQL，包括更强大的优化和允许查询特定时间历史数据的**时间旅行**

## 2. Wildfire 架构

图 1 是  Wildfire 的架构，主要有两个部分：Spark 和 Wildfire 引擎。Wildfire 应用程序的主要入口点是 Spark，为各类大数据分析提供了一个可扩展的、集成生态系统，而 Wildfire 引擎加速应用程序请求的处理，并支持对新摄取的数据进行分析。

> TODO： 图 1

### 2.1 请求的处理

对 Wildfire 的所有请求都通过 Spark API，除了 Wildfire 引擎原生的 OLTP API（稍后讨论）。 **每个请求**都会在一组机器上启动 Spark executor，请求的类型决定了在那些机器上启动。集群中的大多数节点只执行分析请求，并且只需要普通服务器（图 1 中的实线箭头显示了这些节点中的请求和数据流）。其他更强大的节点，具有更快的本地持久存储（SSD 或 NVRAM）和更多内核以提高并行性，同时处理事务和分析查询，这些分析查询需要来自这些事务最新数据（图 1 中的虚线箭头显示了这些节点中的请求和数据流）。

Wildfire 是列式处理引擎，类似于带有 BLU Acceleration [33] 的 DB2。每个 Wildfire 实例守护进程都连接到一个 Spark executor。 引擎有两种类型的守护进程：有状态和无状态。**有状态守护进程**针对最新数据处理事务和分析请求。 **无状态守护进程**仅对（大量）旧数据执行分析查询。

为了通过并行加速摄取，系统中的**非静态表**根据主键（单列或复合列）的前缀在处理事务的节点之间进行分片。为了获得更高的可用性，还将表分片分配给（可配置数量的）多个节点。节点上有状态引擎的守护进程<u>==负责对分配给该节点的数据进行摄取、更新和查找操作==</u>，而无状态引擎的守护进程可以读取共享文件系统中的任何数据以进行分析查询。分布式协调系统（例如 ZooKeeper）管理与分片和复制相关的元信息，**目录**（例如 HCatalog）维护每个表的模式信息。

Wildfire 是开放的，允许任何外部 reader 使用 Spark API 读取 Wildfire 引擎摄取的数据，而不涉及 Wildfire 引擎组件，但外部 reader 将无法查看存储在<u>有状态守护程序</u>上的最新事务数据。此外，为了满足需要大量摄取率的应用程序，Wildfire 为引擎提供了一个原生 API，其中对每个表的插入请求在初始调用后作为 **prepared 语句**保留。

### 2.2 数据的处理和存储

[图 2](#_bookmark4) 说明了 Wildfire 中分片副本中**数据的生命周期**。Wildfire 引擎中的每个事务都将其**未提交的更改**，保存在由一个或多个日志块组成的本地事务 **side-log** 中。 每个日志块只能包含一个表的事务。在提交时，事务将其 **side-log** 追加到 **log** 中，该日志保存在内存和磁盘（SSD 或 NVRAM）上。 此外，为了可用性， **side-log** 被复制到负责维护该分片数据副本的其他节点上。

> TODO： 图 2

虽然分片的任何副本都可以处理对该分片的任何事务请求，但其中一个副本会定期调用**整理**操作。此操作扫描日志，并将来自同一表的多个（已提交）事务的日志块分组在一起，从而创建仅包含来自单个表的数据的更大的**整理块**。 除了合并日志块之外，**整理**还执行一些数据清理，稍后将详细讨论。接着，刷新<u>整理后的数据块</u>到本地 SSD （以进行快速读取）和分布式文件系统（以便其他节点也可以访问它们，例如，HDFS [[6](#_bookmark13)]、S3 [[3](#_bookmark10)]、Swift [[16](#_bookmark23)] , ...) 。<u>整理过程完成后，整理程序将修剪它已成功整理的日志记录</u>。

Wildfire 引擎中查询的输入源是（共享）<u>**整理数据**</u>和（本地的分片）日志。换句话说，每个引擎实例都可以读取任何经过<u>整理的数据</u>，而不管其分片在那，但只能访问它负责的分片日志记录。为避免扫描日志和整理块时，输入流中的潜在重复，引擎会在每个查询开始时检查日志中最后的**整理点**。 需要最新数据的查询（[图 1](#_bookmark1) 中的深红色箭头）的隔离级别是快照隔离。

表的所有元组都使用 Parquet [[9](#_bookmark16)] 格式存储在日志块和**整理块**中。 因此，每个块都包含表中一组行的所有列值，并且这些值以列的形式存储在块内，这有助于只访问查询中用到的列，因此，可以获得更大的分页块。Parquet 布局和本地压缩允许数据块完全独立。

## 3. 事务

尽管采用了列式数据处理，Wildfire 引擎不仅仅是 Spark 生态系统的查询处理器或加速器。它还支持插入、更新和删除的事务。

Wildfire 以跨多个数据中心的高可用性为目标，并允许网络分区。因此，无法提供一致性语义，每次读取不会看到先前所有的写入 [[23](#_bookmark30)] 。现有的高可用性系统，如 Cassandra [[4\]](#_bookmark11) 通常提供最终一致性或强制采用多服务器仲裁读。

然而，最终的一致性对于应用程序的开发者来说很痛苦。考虑来自应用程序的两个连续查询。如果第一个查询被路由到落后的备用服务器，则第一个查询可能会得到第二个查询中遗漏的结果。从多个服务器执行冗余读取的仲裁读是一种合理的选择。然而，它们不仅对于可能读取数千、数百万或数十亿条记录的 OLAP 样式事务不可行，而且对于点查询来说成本也很高。

Wildfire 的目标是高可用性和 ACID，这是不可行的。因此，Wildfire 采用最后写入者获胜 (LWW) 语义对同一键进行并发更新，并对查询的仲裁可读内容进行快照隔离，而无需从仲裁副本中读取数据以满足查询。本节的其余部分描述了实现这一目标的一些设计选择和方法。

### 3.1 Writes: Inserts, Updates, and Deletes

#### 3.1.1 Replication

#### 3.1.2 Shards

#### 3.1.3 Conflict Resolution

### 3.2 Reads

## 4. 分析

Apache Spark 为大数据分析、流处理、机器学习和图处理提供了一个广泛的生态系统。 我们将 Wildfire 集成到 Spark 环境中，以便在其现有功能的基础上进行开发。Spark 缺少对 OLTP 的支持，Wildfire 增强了这点，并提高了其 OLAP 性能。

本节描述 Wildfire 对 Spark 的主要扩展：(1) 新的 OLTP 接口 OLTPContext，(2) 对 Spark Catalyst 优化器和现有 OLAP SQLContext 的扩展，以支持将查询下推到 Wildfire 引擎，以及 (3) 我们在 Wildfire 中支持用户定义函数 (UDF) 和用户定义聚合函数 (UDAF)。

### 4.1 OLTP 的新接口

为了提供 HTAP 功能，我们需要支持 OLTP 操作，即点查询、插入或**更新插入**。但是，目前 Spark 生态系统中缺少此功能。Wildfire 构建了一个可供 Spark 应用程序使用的新 OLTP 接口，称为 `OLTPContext`。 目前，这个接口与 Spark 现有的 OLAP 接口 `SQLContext` 是分开的。<u>这两个接口可能会在 Spark 的未来版本中统一</u>。 我们的 OLTP API 与 Spark 的不同组件配合得非常好。 例如，我们可以将它与 Spark Streaming 一起使用，以实现来自流数据源的高速插入。 我们还可以将此 OLTP API 与 Spark SQL 一起用于 HTAP。

`OLTPContext` 访问并缓存协调服务，以读取后端 Wildfire 集群的配置状态，即 Wildfire 集群和它们管理的分片，以及**目录服务**。为了将事务路由到正确的分片，OLTP 需要分片的唯一标识，例如，通过插入查询中的分片键，或点查询中的可计算的静态谓词。我们的初始原型尚不支持跨越多个分片的事务，但计划在将来实现。确定分片后，`OLTPContext` 将读写路由到相应的 Wildfire 引擎节点，该节点管理相应的分片或分片副本。`OLTPContext` 从协调服务中获取当前分片到节点的分配。如果 `OLTPContext` 无法从查询中识别出分片，例如，点查询没有在分片键上谓词，或者没有识别出唯一的分片，又或者无法静态评估，则 `OLTPContext` 将点查询广播给所有 Wildfire 引擎。然而，这会带来更高的成本，并打破我们当前原型中的事务隔离，因为它可能会导致跨碎片事务。

我们还在 `OLTPContext` 中处理节点故障。 例如，如果负责插入数据的节点出现故障，我们尝试将这些数据重新插入到副本节点之一，并更新主机到分片的映射。

### 4.2 Spark SQL 的 OLAP 扩展

对于 OLAP，我们希望用户能够使用与常规 Spark 表相同的 Spark SQL 接口（通过 Spark DataFrames 或 SQL）查询 Wildfire 表。此外，我们希望能够在同一查询中同时使用 Wildfire 表和普通 Spark 表，例如，将 Wildfire 表与 JSON 表连接起来。

我们通过扩展 Spark SQL 的数据源 API 和 Catalyst 查询优化器来实现这种无缝集成。 Data Sources API 提供了一种通过 Spark SQL 以插件的方式访问 Spark 外部数据源的方法。 Spark 的 Catalyst 优化器目前能够通过数据源 API 将**投影**和**过滤**操作下推到数据源（如果数据源支持）。但是，我们的 Wildfire 引擎为 Spark SQL 提供了更高级的查询功能。我们可以下推更复杂的操作，例如**连接**和部分聚合，以及用户定义的函数和聚合。

这些对数据源 API 和 Catalyst 优化器的扩展是通用的，不仅适用于 Wildfire。可以将任意复杂的查询下推到任何实现我们 API 扩展的数据源，因为这种方法允许源决定可以下推的计划。通过对远程源的这种通用下推方法，我们基本上使 Spark 成为大数据系统的联合引擎。

#### 4.2.1 Data Sources API 的扩展

为了允许更复杂的下推，我们向数据源 API 引入了一种新的数据源，称为 `PushDownSource`。 `PushDownSource` 提供的 API 允许数据源向 Catalyst 优化器表达其下推能力。 给定一个 Spark 逻辑计划（树结构的逻辑查询计划），数据源可以通过这个API表达整个逻辑计划是否可以在数据源中执行。如果无法在数据源中执行，此 API 进一步提供了一种方法来检查数据源是否可以支持计划中的各个表达式，这对于允许部分下推很重要（将在下面提供详细信息）。

#### 4.2.2 Catalyst 优化器的扩展

我们还扩展了 Spark 的 Catalyst 优化器，以便对实现 `PushDownSource` API 的数据源下推查询。更具体地说，我们在查询优化的逻辑优化阶段添加了一些重写规则。每个规则都以通常的方式将查询计划重写为逻辑上等效的计划。它们一起以自下而上的方式确定和构建下推计划，如图 [3](#_bookmark5) 所示。我们从叶节点 `PushDownSource` 开始。它们代表目标数据源中的**一张表**，显然可以下推。然后我们查看每个 `PushDownSource` 的父节点。通过使用扩展 API，Catalyst 知道父级表示的子查询是否可以下推。如果可以，我们构造一个新的叶节点来替换父节点，并跟踪叶节点内部的下推计划。在 Join 的情况下，只有当两个子节点都被下推时，我们才会下推 Join，并且连接本身需要可以被下推（例如，[colocated join](http://doris.apache.org/master/zh-CN/administrator-guide/colocation-join.html)）。这个过程将一直持续直到一个固定点（逻辑计划不再发生变化）。

在许多情况下，我们无法下推由树节点表示的整个子查询，但我们可以重写计划，以便可以下推部分子查询。 图 [4](#_bookmark6) 说明了部分下推的三个最常见示例。

- **部分聚合下推：** 由于包括 Wildfire 在内的许多数据源，不具备在自身之间传输数据以进行查询处理的能力，因此无法完全下推聚合函数。 在这种情况下，我们将聚合计划重写为部分聚合，然后是全局聚合，并将部分聚合下推。例如，为了支持 Wildfire 的 count(.)，它被重写为在所有 Wildfire 引擎上执行的部分 count(.)，然后是在 Spark 中执行的全局 sum(.)。

- **部分投影下推：** 对于投影，如果列表达式列表包含一个或多个不可下推的表达式，我们将投影拆分为两个连续的投影。第一个被下推到数据源中，包含所有表达式所需的基本列，第二个在 Spark 中执行以计算的实际表达式。

- **部分谓词下推：**如果一个**连接**谓词包含一个或多个不能下推的子谓词，我们只下推可下推的子谓词，并与不可下推的子谓词形成一个新的选择节点。(这里的连接是 conjunctive，就是 AND)

### 4.3 为 HTAP 使用 OLTPContext 和 SQLContext

需要 HTAP 的应用程序在 Spark Driver 中实例化新的 `OLTPContext` 和 `SQLContext`。这允许他们通过我们扩展的 `SQLContext` 提交分析查询，并通过 `OLTPContext` 将点查询和插入查询指向 Wildfire。为 OLAP 查询分配一个快照，该快照基于所需的最大可容忍的数据过时性。如果过时时间比**整理**间隔短（通常只有一两秒，但这是可配置的），则查询要么被延迟，直到**整理**赶上快照，要么必须将查询发送到 Wildfire 引擎节点，从本地 SSD 上的日志读取数据。除非可以使用 pruning 分片（分区），否则必须将查询发送到所有 Wildfire 引擎节点。因此，具有这种**短期陈旧性要求**的分析查询成本更高，并且可能会对纯 OLTP 查询的事务吞吐量产生负面影响。然而，这与传统数据库系统没有什么不同，传统数据库系统使用**准入控制**来平衡分析查询和事务查询的资源使用。OLAP 查询可以容忍比 Wildfire 的**整理间隔**更长的陈旧性，可以通过任何节点从共享文件系统读取的数据进行更低成本的处理。

### 4.4 用户定义的函数和聚合函数

从最终用户的角度来看，Spark 和 Spark SQL 的一个关键特性是可扩展性。可以在查询中定义和使用  UDF 和 UDAF。在 Java 8 和 Scala 中使用匿名函数 (lambdas)，使其即强大又易用。因此，Wildfire 还必须支持 UDF 和 UDAFs，并能够在引擎内执行它们。UDF 可用于查询的 `select` 和 `where` 子句。当在聚合函数和谓词内部使用时，或者是 UDAF 函数本身时，它们可以减少返回给 Spark 的数据量。UDF 可以包含难以用 SQL 表达的逻辑（例如，决策树、用于评分的机器学习模型，甚至深度学习模型）。 Wildfire 支持来自 Java 和 Scala 的 UDF 和 UDAF，并在 Wildfire 引擎内运行的嵌入式 Java 虚拟机中执行它们。由于 Wildfire 引擎是在本机代码环境中实现的，因此可以更轻松地使用硬件加速（例如 GPU 和 FPGA）以运行具有更复杂模型的 UDF。

## 5. 原型

我们在 SIGMOD 2016 [[21](#_bookmark28)] 中展示了 Wildfire 的初始原型。 从那时起，我们朝着最终目标增强了这个原型（如[图1](#_bookmark1) 所示）。[图 5](#_bookmark7) 显示了 Wildfire 的当前状态。

SparkSQL 是分析应用程序的入口点，基于 Scala 的接口用于 OLTP 应用程序（**目前只接收请摄取求**）。如 [2.1 节](#_bookmark3) 所述，Wildfire 还为引擎提供了一个原生 API，因为我们针对 OLTP 的 Scala API 在 SIGMOD 期间还很原始，这个原生 API 在当时的演示过程中用于接收摄取请求。ZooKeeper 用作协调服务，HCatalog 是目录信息的主要来源。引擎和客户端层联系 ZooKeeper 以获取分片信息。该引擎还联系 ZooKeeper 以了解副本的状态和每个分片的最后的整理点。引擎的本地存储是 SSD，同时并发处理大量摄取请求与分析请求。**整理（Grooming）** 将数据块同时写入 SSD 和共享文件系统。**<u>根据 LRU 策略（整理时间）和预留的 SSD 空间</u>**清理 SSD 中的块。原型中使用的共享分布式存储系统是一个对象存储，Alluxio [[2](#_bookmark9)] 在顶部充当缓存。

我们目前正致力于将 Wildfire 引擎的 OLTP 接口暴露给 Spark，以便在 Spark 内运行的应用程序可以访问完整的 HTAP 功能。 此外，我们正在扩展 Wildfire 引擎以支持更复杂的数据类型（例如 JSON、数组）。 最后，我们正在改进 Wildfire 中的索引以支持对主索引和二级索引的快速点查询，并致力于支持更复杂的事务。



## 6. 相关的工作

在过去的十年中，尽管已经开发了几种 SQL 处理系统，尤其是在开源 [[18](#_bookmark25)] 中，但没有一个能够同时处理分析和事务工作负载。这些系统中的大多数，包括 Hive [[34](#_bookmark41)]、Impala[[29](#_bookmark36)]、HAWQ [[25](#_bookmark32)]、Big SQL [[27](#_bookmark34)]和 Spark SQL [[19](#_bookmark26)] 最初都专注于对 HDFS 数据的分析。由于 HDFS 和 Hadoop 的重点是批处理，因此数据也是分批摄取的。对于需要更新和更快插入速率的应用程序，NoSQL 系统提供了替代方案。 HBase [[7](#_bookmark14), [35](#_bookmark42)] 和 Cassandra [[12](#_bookmark19), [4](#_bookmark11)] 是用于此目的的两个最流行的 NoSQL 系统。然而，这导致了事务系统与分析系统分离的 lambda 架构。Wildfire 的目的是为事务处理和分析处理提供一个统一的平台。

多年来，一些初始系统，如 Hive 和 Impala，也开始支持更新。Hive 最近支持 ACID 事务 [[13](#_bookmark20)] ，但有一些限制，例如不支持显式的事务开始、提交和回滚语句。另一方面，Impala [[29](#_bookmark36)] 与存储管理器 Kudu [[8\]](#_bookmark15) 的集成，允许 **SQL-on-Hadoop 引擎**处理更新和删除，减少了分别使用 HDFS 和 HBase 进行事务和分析的陷阱。HAWQ[[25](#_bookmark32)] 支持**快照隔离**，使用 PostgreSQL 作为其底层处理引擎，它只允许追加，事务只能在主节点（一个中央固定节点）上提交。 因此意味着，这些系统并不支持大量事务，而是支持**批量插入**和**缓慢变化的维度**，这是典型的数据仓库工作负载。

还有其他系统，如 Splice Machine [[17](#_bookmark24)] 和 Phoenix [[10](#_bookmark17)] 允许更新和事务。它们为存储在 HBase 表中的数据提供 SQL 处理，因此依赖 HBase 进行更新。Splice Machine 甚至支持 ACID 事务。 但是因为对 HBase 表的扫描非常慢，它们不提供快速的 OLAP 功能。大多数情况下将数据转换为更易分析的格式，如 Parquet，并由其他 SQL 引擎处理，例如 Hive、Impala 或 SparkSQL。这种数据复制既容易出错又成本高昂，而且没法对最新数据进行分析处理。

Oracle [[31](#_bookmark38)]、SAP HANA [[26](#_bookmark33)] 和 MemSQL [[14](#_bookmark21)] 是支持**混合分析和事务工作负载**作为独立引擎的系统 ，但它们使用不同的格式进行数据摄取和分析。因此，最新提交的数据不能立即用于分析查询，否则访问最新数据需要在行存储表和列存储表之间进行昂贵的**连接（join）**。在 Wildfire 中，通过对数据摄取和分析使用单一数据格式，我们可以立即对最新提交的数据进行分析。HyPer [[28](#_bookmark35)] 还支持使用多版本并发控制的混合工作负载，并利用 LLVM 生成**机器代码**以获得非常优化的单线程性能。 然而，HyPer 在大规模分布式环境中的表现尚不清楚。

Wildfire 从**内存**到 **SSD/NVM** 再到**共享文件系统**的数据生命周期，受到 BigTable  [[24](#_bookmark31)] 和 MyRock [[15](#_bookmark22)] 等系统中数据移动和合并设计的启发。但是，Wildfire 不是基于 LSM 树 [[32](#_bookmark39)] 。


## 7. CONCLUSIONS

我们展示了 Wildfire 系统，该系统旨在处理大量事务，同时在大规模分布式大数据平台中并发执行复杂的分析查询。分析查询通过 Spark SQL API 发出，每个节点上都有一个 Spark Executor 连接到 Wildfire 的列式引擎。 与 Spark 的连接将 Wildfire 的分析功能暴露给整个 Spark 生态系统，包括图处理和机器学习。Wildfire 还扩展了 Spark 的 Catalyst 优化器来执行复杂的下推分析，并为无法下推到 Wildfire 列式引擎的分析查询的剩余部分生成补偿计划。
