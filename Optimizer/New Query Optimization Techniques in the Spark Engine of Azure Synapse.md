# New Query Optimization Techniques in the Spark Engine of Azure Synapse

## 2 MOTIVATION AND EXAMPLES
We begin with a performance characterization of Spark.



### 2.1 Workload characterization

We enhanced the instrumentation done by Spark to measure the time spent in each operator1 by each task. Figure 2 reports the time spent in various operators for the most expensive 20 queries in TPCDS (at 1TB scale factor). For each query it shows the breakdown before and after our optimizations, we focus on the cost before (left bar) in this section. We make the following observations.

- **Exchange**, hash-aggregate and sort are the three most expensive operators. They contribute to 80% of the total task time in half the queries and 50 − 80% in another quarter of the queries.
- **Exchange** is uniformly expensive and contributes 20 − 40% of the cost in all but a few ( 5%) scan heavy queries.
- Sort and hash-aggregate are almost equally expensive, they together contribute 20 − 50% of cost in most queries.
- Scan and Join, the other two significant operators are much less expensive on average. However, they are the most expensive operator in specific queries (like 𝑄88 and 𝑄95 respectively).

### 2.2 Examples of optimizations
Next we motivate the proposed optimizations with examples from TPCDS. Table 1 describes the notation we use to represent queries.

2.2.1 **Exchange placement**. Consider a variant of Q23 (we show only 2 of the 4 subtrees and modify some operators for ease of exposition) as shown in Figure 3. The tree shows operators as nodes and their required partitioning properties annotated on edges. In case there are multiple possibilities the edge is annotated with a set of partitioning options, any one of which would suffice. For example, edge 𝑒4 requires partitioning on either the pair of columns 𝑎1, 𝑏1 or just 𝑎1 or just 𝑏1. All these are valid options as key based operators (join, group-by etc.) can execute in parallel as long as inputs are partitioned on some subset of the keys. Notice that the query performs 𝑇1 ⊲⊳ 𝑇2 twice but with different parent operators.

An exchange operator takes as input a set of columns (and a partition count) and partitions the data on those columns. Figure 4 shows two ways of placing exchanges in this query. The plan on the left is generated by state-of-the-art algorithms that minimize the number of exchanges needed to satisfy the required properties of all the operators. To do so it picks partitioning options at edges such that they can be satisfied by exchanges introduced lower in the tree. For example, if we pick a partitioning option 𝑎1 at 𝑒8, it can be satisfied by the previous exchange on 𝑎1 at 𝑒6 (we use shorthand 𝑒6 ←𝑎1 to represent exchange assignments). Similarly if the partitioning option 𝑎1 at 𝑒4 is chosen, it can make use of 𝑒1 ← 𝑎1. **We refer to the careful choice of picking partitioning options to use a previous exchange as overlapping an exchange**. Such an assignment would lead to six exchanges (at all but 𝑒8 and 𝑒4). For this example, the above assignment is minimal in the number of exchanges needed to satisfy partitioning requirements of all operators. The exchange reuse rule would then trim this list down to 4 (Figure 4(a) shows the final plan). Note that in this plan the join between 𝑇1 and 𝑇2 is performed twice and the exchanges after 𝑇1 and 𝑇2 are reused and each is read by two consumer stages.

> 我们将谨慎选择分区选项以使用前一个交换称为重叠交换。

However as shown in Figure 4(b) there is another assignment which overlaps fewer exchanges but is better. Consider the plan when only exchange 𝑒3 ←𝑏3 is overlapped (with 𝑒5). This would lead to seven exchange assignments (before reuse exchange). Notice here we deliberately pick the partitioning choice 𝑏1 at 𝑒8 and this is clearly sub-optimal from an exchange overlap perspective. Despite this we get a better plan after the reuse exchange rule is applied (as shown in Figure 4(b)). This plan directly reuses the exchange 𝑒4 ←𝑏1 at 𝑒8 (thus reusing the result of the join) to generate a plan with 4 exchanges.As this is a deeper exchange reuse, this planwould not only avoid exchanges at 𝑒6, 𝑒7 and 𝑒8 but also avoid performing the join a second time. Further note that this plan would also likely lead to lesser I/O as only one exchange is reused as opposed to two (2 reads instead of 4). Hence overall we expect this plan to be better.

In summary, combining exchange reuse opportunities with exchange overlap produces better plans, this is the focus of the exchange placement algorithm we propose.

## 3 EXCHANGE PLACEMENT

This section describes the exchange placement algorithm we use in synapse spark. Figure 7 provides an overview of what existing systems do today and our proposal. Broadly there are two kinds of systems. Scope [35], employs cost based exploration to select among different exchange placement options [34]. As we describe later such exploration allows it to maximally overlap exchanges. On the other hand systems like Spark do not support exploration and instead maintain just a single plan. They traverse the plan bottom up and introduce exchanges after performing a local overlap check. As shown in the figure, both systems apply the **exchange reuse rule** separately, after exchange placement. In both systems, it transforms the final chosen plan without exploration.

In synapse spark we perform exchange placement in a cost based manner, while taking into account both exchange overlap and exchange reuse opportunities. Now, cost based exploration can be expensive, and Scope employs a large optimization time budget (several minutes). In synapse spark on the other-hand we impose a hard constraint on the optimizer time (in seconds) to meet customers expectations. To achieve this we improve the state-ofthe-art algorithm that has a large exploration space (Section 3.1). We do so by exploring multiple options only when there are multiple ways to overlap exchanges or when exchange overlap conflicts with exchange reuse (Section 3.2). Finally, to determine conflicting options, we need to identify potential for exchange reuse early. We employ plan marking for this (Section 3.3).

> 本节介绍我们在 synapse spark 中使用的  exchange placement 算法。 图 7 概述了当今现有系统的功能以及我们的建议。大致有两种系统。Scope [35] 采用基于成本的探索来选择不同的 exchange placement[34]。正如我们稍后描述的那样，这种探索允许它最大程度地重叠交换。另一方面，像 Spark 这样的系统不支持探索，而是只维护一个计划。他们自下而上遍历计划并在执行**局部重叠检查**后引入 Exchange。 如图所示，两个系统在 exchange placement 后分别应用**交换重用规则**。 在这两个系统中，它无需探索即可转换最终选择的计划。
>
> 在 synapse spark 中，我们以基于成本的方式执行 exchange placement，同时考虑交换重叠和交换重用机会。目前基于成本的探索可能很昂贵，而 Scope 使用了很大的优化时间预算（几分钟）。另一方面，我们对 synapse spark 优化器时间施加了硬约束（以秒为单位），以满足客户的期望。为了实现这一点，我们改进了具有较大探索空间的**现有**算法（第3.1节）。只有当有多种方式重叠交换或交换重叠与交换重用冲突时，我们才会探索多个选项（第3.2节）。最后，为了确定相互冲突的选项，我们需要尽早识别交换重用的可能性。我们为此采用了计划标记（第3.3节）。

### 3.1 Exploration based exchange placement
Lets begin by examining the state-of-the-art algorithm for exchange placement [34]. Algorithm 1 shows pseudo-code for a recursive routine that computes the interesting partitioning options at each operator in the plan. For ease of exposition, we assume that the plan only consists of key based operators. The implementation of course deals with all SQL operators. First, we define P′(X) = P(X) \ ∅ where P(X) is the **power set of X**. In the this section when we mention power set, we refer to P′. Now in this method, the interesting partitioning options consists of all possible combinations of the operator keys i.e. P′(plan.keys). In Figure 3, the join having {𝑎1, 𝑏1} as keys, would have {𝑎1 |𝑏1 |𝑎1, 𝑏1} in its `iKeysSet`.

Next, plans with different combinations of partition keys are explored using a standard plan space exploration algorithm. Algorithm 2 shows a simplified version of the dynamic programming based exploration algorithm used in both synapse spark and Scope^2^. The algorithm tracks up to 𝑘 plans per node. We discuss how 𝑘 is chosen at the end of the section.

> 2. There are several differences in the specifics of the algorithm used by the two systems. We focus here on exchange placement relevant aspects.

In line 2, for each interesting partitioning key `partnKeys` of this operator, the best (up to 𝑘) plans for its children are computed first. Next, these alternative plans from the children are combined to get the alternative plans for the current operator. For example, if the plan has two children 𝐶1 and 𝐶2, **having two and three top plans** respectively, there would be six alternative options - plan having children as $\{\{C_{1}^{1}, C_{2}^{1}\},\{C_{1}^{1}, C_{2}^{2}\},\{C_{1}^{1}, C_{2}^{3}\},\{C_{1}^{2}, C_{2}^{1}\},\{C_{1}^{2}, C_{2}^{2}\},\{C_{1}^{2}, C_{2}^{3}\}\}$. This is followed by iterating over these alternatives, adding exchanges (using `EnforceExchange` at line 9) and selecting the top 𝑘 plans having minimum cost. EnforceExchange, as explained in more detail in [34], inserts an exchange only if the child partitioning does not satisfy the partitioning option at the parent. Specifically it checks for **exchange overlap**, that is whether the child partitioning is a (non-empty) subset of the partitioning option being explored.

This algorithm is exhaustive in the enumeration of interesting partitioning options. Scope, the existing system that uses the algorithm, can afford to employ a large value of 𝑘 (as it has a large time budget). This ensures that it is able to produce maximum overlap plans like the one shown in Figure 4(a).

### 3.2 Pruning the space with overlap reasoning

Algorithm 3 describes our implementation to prune the exploration space by reducing the partitioning options (lines 5-7). Instead of relying on `EnforceExchange` to detect overlap opportunities, we prune the options in two phases. First, we compute individual partitioning keys of the operator that have an overlap with its parent’s or children’s keys. We add^3^ all of them to set `iKeys`

> 3. X.addAll(Y) indicates adding all elements from Set Y to Set X. X.add(Y) indicates adding the Set Y to Set X as a single entity.

In the second phase, we obtain all overlap options by intersecting the power set of iKeys with the power set of parent’s keys and the children’s keys. We insert only these as options (in iKeySet) using a `checkAndAddAll` method. This method checks if the number of distinct values for the set is more than the number of partitions required (a job parameter) before adding it as a partitioning option. Table 2 demonstrates how this adds all overlap options. The third row (labeled Total) has 3 different ways to overlap between parent (P1) and child (ST1), all these are added as options. Row Partial (representative of example in Figure 3) only adds one option. This is sufficient to produce maximal overlap plan Figure 4(a). Finally, if no options are added based on overlap (row None in table), we only consider one option which is the entire key set (line 20). This pruning reduces the search space significantly whenever operators are keyed on multiple columns (like in TPCDS queries).



### 3.3 Incorporating exchange reuse

> As we saw in Section 2.2.1 exchange reuse can conflict with exchange overlap. This happens when there is an overlap between partitioning keys of the reusable sub-tree and its parent. For example, in Figure 3, there is an overlap in the partitioning keys of join having keys {𝑎1} and its parent join having keys {𝑎1, 𝑏1}. If we simply maximize overlap we may not introduce an exchange after the join at all and hence there would be no scope for an exchange reuse (after **join**).
>
> To resolve this, ==we will have to include additional keys in the interesting partitioning options (`iKeysSet`) tracked at the parents of the reusable sub-trees==. We accomplish this in two steps.
>
> We begin by executing a new **routine** before Algorithm 3 which is described in Algorithm 4. This algorithm adds **plan markers** at nodes in the tree such that if two nodes have the same marker value, **the sub-trees rooted on them are identical**. In addition to it, we use a `reuseMap`, to store <u>the partitioning keys from these identical subtrees’ parent</u>. This algorithm is followed by a cleanup routine (not shown) that removes **singleton entries** from the `reuseMap`.
>
> Next, we extend Algorithm 3 to support exchange reuse by adding the common keys (derived from `reuseMap`) in the interesting partitioning keys set if the child is a reusable sub-tree (lines 13-16).

正如我们在 2.2.1 节中看到的，**交换重用**可能与**交换重叠**发生冲突。当可重用子节点的分区键与其节点之间存在重叠时，就会发生这种情况。例如，在图 3 中，具有键 {𝑎1} 的 Join 的分区键与其具有键 {𝑎1，𝑏1} 的父 Join 的分区键存在重叠。如果我们只是最大化重叠，我们可能根本不会在 Join 之后引入 Shuffle，因此（在 **Join** 之后）没有交换重用的空间。

为了解决这个问题，==在可重用子树的父节点上跟踪的**有趣分区选项**（`iKeysSet`）中，必须包含额外的键==。我们分两步完成。

我们首先在算法 3 之前执行一个新的**例程**，在算法 4 中描述。该算法在树中的节点处添加**计划标记**，这样如果两个节点具有相同的标记值，**则以它们为根的子树相同**。 除此之外，我们使用 `reuseMap` 来存储<u>来自这些相同子树父节点的分区键</u>。该算法之后是一个清理例程（未显示），该例程从 `reuseMap` 中删除**单例条目**。

接下来，如果子树是可重用的子树（第 13-16 行），我们通过在==**有趣的分区键集**==中添加公共键（派生自 `reuseMap`）来扩展算法 3 以支持**交换重用**。

Lets revisit row `Partial` in Table 2. Consider the two nodes at (𝑆𝑇1, 𝑆𝑇2) at ⊲⊳𝑎1=𝑎2 (𝑇1,𝑇2) in Figure 3 and their parents (𝑃1, 𝑃2). We already established that their `iKeysSet` based on overlap reasoning would contain one element 𝑎1. Now in order to take reuse into account, we will add the common keys between the 𝑃1 and 𝑃2 in their `iKeysSet`. Thus, the parents’ new `iKeysSet` would be {𝑎1 |𝑏1}. The exploration will now include exchange on 𝑏1 as an option. If costed right this should lead to the plan shown in Figure 4(b).

Since, we are depending on the costing model for the keys selection, we need to ensure that during costing we take exchange reuse into account. To accomplish this, we add a sub-routine `AddReuseExchange` after line 9 in Algorithm 2. At this point, optPlan would contain exchange operators at the required places, added by `EnforceExchange`. Since we have previously accomplished plan-marking, AddReuseExchange will identify exchange operators, whose children are marked for reuse. Now, for each group (consisting of identical sub-trees), it replaces all except one such exchange operators by exchange reuse operators in the optPlan. We will now use this optPlanWithReuse while updating the operator’s top k plans set.

```
optPlanWithReuse ← AddReuseExchange(optPlan)
```

> In summary, synapse spark incorporates cost based exploration to decide on the placement of exchanges. By detecting exchange reuse opportunity early and by using this along with overlap information it is able to prune the search space significantly to make exploration practical. Specifically, in synapse spark we desire to optimize every query within 30 seconds.We achieve this by dynamically choosing the values of 𝑘 based on the complexity of the query. We observe that because of pruning a value of 𝑘 = 4 is sufficient to find the optimal exchange placement for all queries. We show in Section 7.4 that a value above 16 (as would be needed without pruning) significantly slows down the optimizer.

总之，**synapse spark** 结合了基于成本的探索来决定交换的位置。通过尽早发现交换重用机会，并将其与重叠信息一起使用，可以显著削减搜索空间，使探索变得切实可行。具体来说，在 synapse spark 中，我们希望在 30 秒内优化每个查询。我们根据查询的复杂性动态选择 𝑘 的值来实现这一点。我们观察到，由于剪枝，𝑘 = 4 足以为所有查询找到最佳交换位置。我们在第 7. 4节中说明，如果 𝑘 大于 16（在没有剪枝的情况下需要），优化器的速度会显著降低。
