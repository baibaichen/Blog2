**Good morning/afternoon, thank you for having me.**

My name is Chang Chen. I’m a software engineer with over 25 years of experience, specializing in database development, big data systems, and high-performance computing.

I have spent the past 14 years deeply involved in C++ and large-scale distributed systems. I’m an Initial Committer and PMC member of **Apache Gluten (Incubating)**, where I led the project from concept to Apache incubation, achieving **double the performance** of Vanilla Spark in key workloads.

Throughout my career, I’ve held senior technical roles at companies like **Kyligence**, **Yihaodian**, and **Rovi Corporation**, focusing on big data platforms, query optimization, and real-time analytics. I’ve led architecture design, performance optimization, and cross-functional teams—successfully delivering production-ready solutions at scale.

I’m passionate about open-source innovation, performance engineering, and building robust data systems. I’m excited about the opportunity to contribute my expertise in database and big data technologies to your team.

Thank you again for this opportunity. I’m happy to answer any questions.

## 背景

19 年加入 Kyligence 就开始解决**交互式查询性能**问题，中间做了很多尝试，但都是一些点上的尝试，比较重要的是

1. 引入了基于 JVM 堆的 Local Cache，特定场景下有价值，但没有本质的提升。
2. 使用 LazyOr，大幅提升 `RoaringBitmap` 的聚合性能。

> [!NOTE]
>
> 为什么这些技术不行？
>
> 1. local cache + soft affinity，在一个繁忙的集群里，数据实际会在每个节点一份。
>
> 2. 缓存击穿之后，性能变慢
>
> 3. LazyOr，聚合上卷的时候不维护基数。但是无法突破 JVM 的限制。
>
> 【可讲】都是通过翻看论文发现提升点

都没有本质的提高，正好 Photon 论文的发表证明 Native Engine 是正确的方向，所以在 22 年和 Intel 合作搞 Gluten 提升 Spark 的性能，因为 Velox 不成熟，而我们相对比较了解 Clickhouse，双方各自选择了一个后端来支持，但前端都采用 Spark。

> [!NOTE]
>
> **为什么 Kyligence 使用 Spark 做交互式查询引擎**？
>
> Kyligence 起源于解决 Hive 查询的性能问题，最开始采用 MR 做离线预计算生成物化视图，使用 Calcite 选择物化视图并做单机查询，因为不是分布式架构，查询一复杂就容易失败，比如不能完整匹配视图，存在后聚合。Spark 兴起之后，离线和交互式查询都使用 Spark 做引擎，解决了单机查询遇到的问题。当然我们现在知道，Spark 不是一个好的交互式查询引擎（code gen 时间较长，shuffle 落盘，单线程调度，SQL parser 较慢）：
>
> 1. 小查询（数据量 <= 1 GB），有一些固定开销，性能到了 1s 之后，就很难再提升了，对那种数据量只有几 MB 或者几 KB 的查询影响尤其大。
>
>    > 一个痛点是索引数据量越小越不好向用户解释性能为啥不如旧版本。
>
> 2. 复杂查询，虽然有明显提升，但是随着 Clickhouse 流行，客户的预期也越来越高。

## 我在 Gluten 的两个角色

早期主要是  Manager 的角色，后期开始做研发的工作，主要集中在数据湖集成方面。

### 角色一：技术负责人（管理 ）


#### 1. 技术可行性调研

首先要回答，**是否可以用 Clickhouse 替代 Spark 原生的 JVM 执行层，从而突破性能瓶颈**？围绕四个维度展开调研：


| 维度 | 分析结论 |
|------|---------|
| **性能潜力** | 在 TPC-H 100 规模下，初步集成后性能提升约 2x，主要来自 Shuffle 和聚合算子加速 |
| **功能覆盖** | CH 不支持完整 Join 类型（如 anti join、non-equal join）、Window Function 较弱；需补充兼容层 |
| **生态兼容** | 原生 Parquet Scan 性能差，无 Page Index 支持；HDFS/S3 支持依赖外部库 |
| **可集成性** | CH 无标准 API，但执行引擎模块化程度高，可通过 JNI + 动态链接方式嵌入 |

📌 **关键技术挑战**：

- **Shuffle 性能优化**：首先解决 hash shuffle，跑通端到端流程。

- **找到后续需要解决的问题**：比如不支持的 Join 类型

- **重要的性能短板**：Parquet scan 性能较差，某些场景不及 Valina spark

✅ **结论**：ClickHouse 具备作为后端的潜力，但需解决三大问题：

1. 缺乏标准化接口 → 工程化的解决方案
2. Parquet 读取性能不足 → Page Index
3. SQL 兼容性差距 → 排解决优先级

> [!NOTE]
>
> **技术细节**：
>
> Shuffle：
>
> 1. 实现一个抽象的 `IColumn::insertRangeSelective` 接口，因为 Shuffle 是按 key 重新分配数据，每行数据都有一个确定的位置。不同的列有不同的内存布局，不同的列类型需要采用不同的实现，比如 `ColumnAggregateFunction` 需要针对不同的聚合函数的缓冲区调用不同的 merge。
>
> 2. Map 和 reduce 比较多时，还是要参考 Spark 的方案，要Sort shuffle。使用 hash shuffle 有 OOM。
>
>    | 方面          | Hash Shuffle (无排序)             | Sort Shuffle (有排序)   |
>    | :------------ | :-------------------------------- | :---------------------- |
>    | 文件数量      | **M * R** (巨大，导致瓶颈)        | **2 * M** (可控)        |
>    | 写入模式      | 随机写 (效率低)                   | 顺序写 (效率高)         |
>    | 读取模式      | 随机读 (效率低)                   | 顺序读 (效率高)         |
>    | 压缩效率      | 低                                | **高** (数据有序)       |
>    | CPU 开销      | 低                                | **较高** (需要排序)     |
>    | 内存开销      | 高 (同时维护多个文件句柄和缓冲区) | 相对较低 (可溢出到磁盘) |
>    | Reduce 端合并 | 复杂，可能需要全排序              | 简单，高效的 K 路归并   |
>
> 3. 分区，排序，序列化（encode），压缩
> 
> 兼容性：
>
> 1. 主要各种特殊的 Join实现，比如 TPCH 16 的 `isNullAwareAntiJoin`，TPCDS 的 Exist-Join；标准的 no equal join 当时也没有实现。
>
> 2. 和 spark 的兼容性的问题，太多细节了。印象比较深的是
>    1. Decimal AVG 函数，中间结果是 float 导致结果不准
>    2. 日期

#### 2. 工程化建设

为推动 Gluten 成为可维护、可扩展、可共建的工程体系，我主导了以下工作：

🔹 **架构设计原则**：
- 解耦 ClickHouse 主干代码：通过自动化 Rebase 脚本每日同步上游变更，确保新特性快速集成。
- 模块化设计：Gluten 自身独立仓库，CH 修改尽量回到上游 repo，便于升级与维护。

🔹 **降低社区参与门槛**：
- GitHub 托管 + CI/CD 全流程自动化；
- 集成进 CICD 的自动化压测框架
- 定期组织线上社区会议，吸引外部贡献者。

🔹 **内部产品集成验证**：
- 将 Gluten 集成进公司核心 OLAP 产品，用于加速预计算与即席查询；
- 建立云上双跑测试框架，监控性能波动与内存泄漏（虽未完全自动化，但已形成例行机制）；
- 明确开发 Scope，优先完善公司业务，让业务方看到实际收益。

🔹 **日常运维与风险控制**

- 协调 ClickHouse 版本合并冲突，保障主干更新顺畅；
- 推动质量保障体系建设，建立性能基线监控机制。

> [!NOTE]
>
> **上线细节**
>
> 1. 可观测性，正确性优先，不比 Valina Spark 性能差。 
> 2. 为了解决没有测试人员的困境，推动团队实现自动化双跑架构，收集每天运行的真实 SQL，第二天周期地压测（基于 Locust），即测性能，也测正确性。这里双跑的关键是**数据安全**，需要公司层面去找种子用户。
> 3. 发现问题：正确性（不兼容的函数），性能，CH Join 导致的 OOM，
> 4. 关于 Fallback：自身的产品发现 fallback 就解决，没有 UDF 问题
> 5. 内存泄漏，第一次上线的时候没有长时间运行，导致有内存泄漏没有发现，后续上线的时候，规定必须运行 24 小时才能上线。
>
> 关于 fallback 的思考：
>
> 1. 不要来回在 jvm 和 native 之间转换数据，只转一次
> 2. 主要来源是 UDF，长期来说要开发出基于从 native 的 udf 框架。

#### 3 竞品分析

我们将 StarRocks 作为主要参照对象，找到优化方向。

| 维度           | Gluten 优势                   | 当前差距                                     |
| -------------- | ----------------------------- | -------------------------------------------- |
| **稳定性**     | 复用成熟 Spark 生态，调度稳定 | ✅                                            |
| **优化器能力** | 基于 Spark CBO，规则较保守    | ❌ Join Reorder 不够智能，缺乏 Runtime Filter |
| **执行模型**   | 存算分离，支持各种部署方式    | ❌ 单线程 Task 调度成为并发瓶颈               |

📌 **关键性能瓶颈分析**：

1. **优化器有差距**
   1. Join Reorder & Runtime Filter： Apache Spark 社区在这两块投入不多。一方面 Spark 优化器采用 System R 风格， Join Reorder 与物理实现分离，确实可能会错过全局最优解，另一方面，社区希望用 Runtime Filter 和 AQE 去减缓这个缺陷。另外我们发现 AWS 的 Runtime filter 也有一些不错的地方。
   2. 优化规则
      1. *Subquery Elimination Using Window Aggregation*，TPCH 17 收益明显。
      2. 部分聚合下推
2. **执行层面的差距**，这里是基于交互查询的来讨论的，存算分离的架构对离线 ETL 有优势。CH 本身的基础设施比如内存管理，执行引擎、缓存和算子比如分组，排序，函数，都还不错。除了 Join 算子稍微差点外，主要是 Right Join 和 non equal Join 性能不好。它主要的问题是在和 Spark 的架构有冲突，
   1. 首先，Spark 是基于 Task 做单线程调度的，基于 JVM 的执行引擎这个问题不严重，Native Engine 并发小查询会导致这里是瓶颈。
   2. 其次，最突出的是无法实现 work steal，Spark 是在 Driver 调度 task，只能在 Driver 层面做推测执行调度。MPP 是根据节点分配工作负载，可以在节点内部实现 Work steal，这一块的性能大约有 20% 左右的提升。这也是我们发现，像 TPCH Q1 这种只有分组的查询总是比 StarRocks 慢 20%。
   3. 最后，因为 Spark 不重视交互式，它的 sql parser 和 analyzer 在复杂 sql 上表现不佳。

### 研发角色

1. 使用 HeapTrack 查内存泄漏

   > [!IMPORTANT]
   >
   > 因为是拦截了 `malloc`，不能使用 jemalloc（没有 export），一致没有加入 CI，人工周期性的检测。
   >
   > 其他的没有跑成功，比如 jemalloc 自带的 profiler。

2. 基于 `libjsig.so`  提供的**信号链（Signal Chaining）机制**获取 JNI 异常信号

   > [!IMPORTANT]
   >
   > **异步安全的信号处理**  信号处理程序在极其受限的环境中运行，大多数 C/C++ 函数不能安全调用。该使用管道来安全地将信号信息从信号处理上下文转移到正常线程，在那里可以安全地执行完整的处理。
   >
   > **堆栈跟踪捕获** 当接收到信号时，采用 clickhouse 的功能捕获堆栈跟踪
   > **线程分离处理信号**  在独立线程中处理每个捕获的信号，避免在处理一个信号时阻塞其他信号的接收。

3. 支持了 Parquet 的 Page Index，在 Parquet 读取阶段引入 Page Index 跳过机制，结合谓词下推，显著减少无效数据扫描，提升 I/O 效率。

   > [!IMPORTANT]
   >
   > 某些情况下比 spark jvm 的 Parquet reader 还慢
   >
   > 1. Parquet 编码大量利用字典格式，Spark 是延迟物化，CH 是直接解码出来
   > 2. 不支持 Page Index
   > 3. 不支持真正的 filter 下推
   >
   > 
   >
   > Parquet 是按行而不是页对齐，因此利用 Clickhouse 提供的功能将表达式树转换为逆波兰表示法，然后求出合法的、基于行的范围，然后过滤掉不需要的 Page。提供给 Parquet reader 的数据是合法的、过滤后的基于 Page 的数据。
   >
   > Skip IO => 收益最大
   >
   > Skip Decompress => 收益适中
   >
   > Skip Decode => 过滤的时候还是要先解码，某些 bit packing 编码的可以做到不用解码就过滤，但效果如何要评估
   >
   > Skip Output => 减少内存 copy

4. 重构了写 Parquet 的 pipeline，和 Delta 的写更加兼容，

   > [!IMPORTANT]
   >
   > 1. Spark 3.3 的实现的机制，导致写 Parquet 必须得分为两块，需要修改源码。Spark 3.5 之后读和写可以合并成一条 Pipeline 不用再修改 Spark 源码。
   > 2. 初版实现没有做列统计，对于 Delta 的查询不友好，特别是如果要支持 Liquid Cluster，必须要有列统计信息。
   > 3. 具体策略，数据处理全部走 Native engine 提高性能，返回 Delta 提交事务需要的数据，比如统计信息；利用 Delta 的功能实现事务和文件优化机制。
   > 4. 实现 Optimized Write，本质就是 adaptive shuffle（由我指导，团队成员实现） 机制。
   >
   > 收益，可以使用 Delta Lake 文件优化（Optimize）机制

5. 支持 Iceberg 的 Parquet 读，equality read 和 Positional Deletes。

   > [!IMPORTANT]
   >
   > 1. 首先支持 Row index，前面做 Page index 过滤的时候其实已经获得了row index
   > 2. Equality Deletes：构建过滤表达式，单列就是 `c1 not in ..`，多列就是 `c1 <> xx or c2 <> xx`
   > 3. Positional Deletes：构建 Deletion Vector，基于 `RoaringBitmap`，读 Delta 也需要用到。
   >
   > Iceberg 这块的设计没有 Delta 好，后续也在改成 DV。

## Gluten 半年规划


###  选项 1 功能：数据湖

Iceberg 被 DB 收购，所以选择优先支持 Delta。

####  Delta

已经实现了 Deletion Vector 读写；使用 Spark Structure Stream 打通 CDC 实时入湖（支持无状态的算子）；可以利用 Delta 自动文件优化机制优化小文件。下一步：

1. 支持窗口聚合和流式 SQL，构建完整的流批一体能力。
2. Delta Liquid Cluster 支持，经我们验证，相比与分区表，Liquid Cluster 可以显著避免小文件带来的性能恶化的场景，有小量功能的开发，需要为 Liquid Cluster 开发一个类似 DPP 的规则，写则需要支持 Hilbert Clustering。注，如果要支持 Spark 3.5，需要 Cherry Pick 4.0 的一些 commit。
3. 更深入的技术调研
   1. Delta 的 CDC 功能
   2. 如果支持 Delta 查询中广泛使用的匿名 UDF 如何支持？
   3. 流式 SQL，以 SQL 的形式创建流式作业。
   4. 支持读取 MySql Binlog 或者 PostgreSQL WAL。

### 选项 2 性能：优化器

我曾经过一篇关于 Azure Synapse Spark 查询优化器的论文，其中提到的 **Exchange 放置优化**，核心思想是**最大化 shuffle 数据的复用**（exchange reuse），减少重复的数据分发。这没有增加物理算子，可以**快速应用到 Gluten**中，没有开发成本。

论文中另一个让我印象深刻的点是**部分聚合下推**（Partial Aggregation Pushdown）。Gluten 曾尝试引入类似规则（由 eBay 团队贡献），但由于缺乏精准的成本估算机制，导致新性能回退比较多，稳定性不足。**Synapse Spark 引入了基于成本的决策模型**，能够判断下推是否真正有益，从而避免无效或负收益的优化。因为引入了新的逻辑算子，不确定是否有开发工作量。 

> 这让我联想到 Kylin 的预计算场景。我们曾遇到两张事实表直接 join 导致性能较差的情况，解决方案是将其中一张事实表预先聚合，生成一个轻量化的索引表，再与另一张表进行 join。这种“大表转小表”的优化策略，本质上与论文中的部分聚合下推思想**高度一致**。

总之，Native Engine 和优化器是两个几乎正交的领域。一些在 Fabric spark 证明有价值的优化，应该可以快速用上。

不过，长期来看我认为，当前更关键的优化方向是**基于统计信息的 Join Reorder**。在这方面，StarRocks 的实现给我留下了深刻印象，如果 Gluten 能在具备统计信息的前提下，实现类似的 join 重排序能力，将极大提升复杂查询的性能。

###  选项 3 性能：执行引擎

> 短期来说是文件系统的 Local cache，要扩展 Clickhouse 文件系统的 local cache，目前它不支持跨进程的共享。

长期可探索 Work Steal 机制，在分布式 Gluten 集群中实现较复杂。随着云上 CPU 能力提升，用户选择 scale-up（如 128 core 单机）执行离线 ETL 更具性价比——相比 8×16c，计算力相当但管理成本更低。若缺乏相应优化，单节点大负载 ETL 将无法发挥性能优势。

# 问题

1. 衡量 Fabric 成功的关键指标有那些？目前大概是什么进度？
2. 我知道这个职位是招聘 Gluten 的研发，Gluten 在微软成功的关键指标是什么？预期什么时候达到？
3. Azure Synapse 的论文中提到了 Exchange Reuse 和成本驱动的部分聚合下推。我想知道这些优化在 Fabric 中的落地情况如何？未来是否会进一步引入基于代价的 Join 重排序能力？”
4. 随着 AI 越来越深入地集成到数据平台，比如生成查询、推荐可视化，Fabric 是否正在向‘AI-native 数据平台’演进？也就是说，AI 不只是个辅助功能，而是成为元数据管理、查询优化甚至调度决策的一部分？



> # 🎯  面试提问策略表
>
> | 问题主题                                      | 技术面提问（面向工程师/架构师）                              | 管理面提问（面向经理/总监）                                  |
> | --------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
> | **1. 成功维度**<br>（衡量 Fabric 成功的关键） | **中文：**<br>从技术角度看，Fabric 的核心价值在于统一架构。想请教一下，团队在评估平台演进时，最关注哪些技术维度的进展？比如系统整合的深度、性能一致性，或是跨服务元数据的打通程度？目前整体处于什么阶段？<br><br>**English：**<br>From a technical perspective, Fabric’s value lies in its unified architecture. Could you share what technical dimensions the team prioritizes when evaluating progress — such as depth of integration, performance consistency, or cross-service metadata unification? Where do we stand today? | **中文：**<br>想请教一下，从战略角度看，团队在衡量 Fabric 成功时，最关注哪些维度？比如客户采纳速度、生态协同效应，或是长期平台竞争力？与主要竞争对手相比，Fabric 当前处于怎样的市场和技术定位？<br><br>**English：**<br>Could you share what strategic dimensions the team focuses on when measuring Fabric’s success — such as customer adoption velocity, ecosystem synergy, or long-term platform competitiveness? And how would you position Fabric relative to key competitors today, both in the market and from a technology standpoint? |
> | **2. 岗位价值**<br>（Gluten 的成功标准）      | **中文：**<br>我知道这个职位聚焦 Gluten 的研发。从工程角度看，衡量 Gluten 在 Fabric 中成功的关键技术标准是什么？比如查询延迟降低、资源利用率提升，还是与 OneLake 的集成稳定性？团队预期在什么时间范围内看到显著成果？<br><br>**English：**<br>I understand this role focuses on Gluten development. From an engineering standpoint, what are the key technical success criteria — such as reduced query latency, improved resource efficiency, or stable integration with OneLake? What’s the expected timeline for meaningful impact? | **中文：**<br>我知道这个职位负责 Gluten 的研发。想请教一下，从团队目标来看，Gluten 被期望在 Fabric 生态中扮演什么角色？它的成功会如何影响整体平台的竞争力或客户体验？团队希望在多长时间内看到关键里程碑？<br><br>**English：**<br>I understand this role is responsible for Gluten development. From a team strategy perspective, what role is Gluten expected to play in the Fabric ecosystem? How would its success impact overall platform competitiveness or customer experience? What’s the timeline for key milestones? |
> | **3. 优化器演进**<br>（查询优化的未来）       | **中文：**<br>我读过 Azure Synapse 的论文，里面提到 Exchange Reuse 和成本驱动的部分聚合下推。这些在 Fabric 中已有体现。想了解下，这类优化目前的落地成熟度如何？未来是否也在探索基于代价的 Join 重排序，来进一步提升复杂查询的性能边界？<br><br>**English：**<br>I’ve read the Azure Synapse paper on Exchange Reuse and cost-driven partial aggregation pushdown — which we’re seeing in Fabric. How mature are these optimizations today? Is there also exploration into cost-based Join Reordering to push the performance envelope for complex queries? | **中文：**<br>Fabric 在查询性能上做了很多创新，比如 Exchange Reuse。我想了解，这类底层优化在团队的技术优先级中处于什么位置？它们是作为短期性能提升手段，还是长期架构演进的一部分？<br><br>**English：**<br>Fabric has introduced several low-level query optimizations like Exchange Reuse. Where do these fit in the team’s technical priorities — are they short-term performance wins, or part of a long-term architectural evolution? |
> | **4. AI-native 演进**<br>（AI 与平台融合）    | **中文：**<br>Fabric 正在深度集成 AI，比如 Copilot 生成 SQL。我在想：是否有计划让 AI 更深入地参与系统决策？比如基于语义理解优化查询计划，或利用历史模式自动调整调度策略？这是否意味着我们正在向‘AI-native 数据平台’演进？<br><br>**English：**<br>AI is becoming deeply integrated — like Copilot generating SQL. Is there a vision to involve AI more directly in system decisions? For example, using semantic understanding to optimize query plans, or leveraging historical patterns for adaptive scheduling? Does this point toward an “AI-native data platform”? | **中文：**<br>随着 AI 在 Fabric 中的渗透加深，比如生成查询、推荐可视化，我想请教：团队是否在将 AI 从“辅助功能”升级为“平台核心能力”？这种转变会如何重塑 Fabric 的长期定位和客户价值？<br><br>**English：**<br>As AI becomes more embedded — generating queries, suggesting visuals — is the team evolving AI from a “helper feature” to a “core platform capability”? How might this shift redefine Fabric’s long-term positioning and customer value? |
>
> ---
>
> ### 📌 使用说明：
>
> - ✅ **技术面**：选择“技术面提问”列，适合与工程师、架构师对话，展现你的**技术深度与工程判断力**。
> - 🧑‍💼 **管理面**：选择“管理面提问”列，适合与经理、总监交流，展现你的**战略思维与业务影响力意识**。
> - 💬 每个问题都以“请教”“想了解”开头，语气谦逊但不失专业。
> - ⏱️ 每个问题控制在 **30–45 秒** 内说完，留出空间给面试官回应。
>
> ---
>
> 需要我将此表格导出为 **PDF 文件** 或 **Markdown 格式** 以便你保存使用吗？我可以立即生成。祝你面试顺利，成功加入微软 Fabric 团队！🚀
