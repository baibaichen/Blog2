# Delay Scheduling：A Simple Technique for Achieving Locality and Fairness in Cluster Scheduling

## 概要

随着组织开始将 Hadoop 和 Dryad 等数据密集型<u>集群计算系统</u>用于更多应用程序，越来越需要在用户之间共享集群。然而，调度中的**公平**和**数据局部性**（将任务放置在包含其输入数据的节点上）之间存在冲突。我们通过为 Facebook 的 600 节点 Hadoop 集群设计公平调度程序的经验来说明这个问题。为了解决局部性和公平性之间的冲突，我们提出了一个简单的算法，称为**延迟调度**：当接下来根据公平性应该调度的作业无法启动本地任务时，它会等待一小段时间，让其他作业启动任务代替。我们发现延迟调度在各种工作负载中实现了近乎最佳的数据局部性，并且可以在保持公平性的同时将吞吐量提高多达 2 倍。此外，延迟调度的简单性使其适用于公平共享之外的各种调度策略。

## 1. 简介

像 MapReduce [18] 和 Dryad[23] 这样的集群计算系统，最初是针对批处理作业（例如 Web 索引）进行优化的。然而，最近出现了另一个用例：在多个用户之间共享一个集群，这些用户在一个公共数据集上混合运行长时的批处理作业和短的交互式查询。共享可以实现统计复用，与为每个组构建单独的集群相比，成本更低。共享还导致了（不同数据集的）数据整合，避免了跨集群的昂贵数据复制，并让用户<u>有效地跨不相交的数据集</u>运行查询。本文，我们探讨了在用户之间共享集群的问题，同时保持 MapReduce 等系统的效率——特别是，保持**数据局部性**，即在其输入数据附近放置计算。 局部性对于大型集群的性能至关重要，网络平分带宽成为瓶颈[18]。

我们的工作最初是由 Facebook 的 MapReduce 工作负载推动的。 来自 Facebook 网站的事件日志被导入一个 600 节点的 Hadoop [2] 数据仓库，用于各种应用程序，包括商业智能、垃圾邮件检测和广告优化。 仓库存储 2PB 的数据，并且每天增长 15 TB。 除了定期运行的“生产”作业外，该集群还用于许多实验性作业，从多小时机器学习计算到通过 SQL 接口提交给名为 Hive [3] 的 Hadoop 的 1-2 分钟即席查询。 该系统每天运行 7500 个 MapReduce 作业，供 200 名分析师和工程师使用。

当 Facebook 开始构建其数据仓库时，发现共享集群提供的数据整合非常有益。然而，当足够多的组开始使用 Hadoop 时，由于 Hadoop 的 FIFO 调度程序，作业响应时间开始受到影响。这对于生产作业来说是不可接受，并且无法进行交互式查询。为了解决这个问题，我们设计了 Hadoop Fair Scheduler，在本文中称为 HFS。HFS 有两个主要目标：

- **公平共享**：使用最大-最小公平共享[[7](https://en.wikipedia.org/wiki/Max-min_fairness)]划分资源以实现<u>统计复用</u>（statistical multiplexing）。例如，如果有两个作业正在运行，每个作业应该得到一半的资源； 如果启动第三个工作，每个工作的份额应该是 33%。
- **数据局部性**：将计算置于输入数据附近，以最大化系统吞吐量。

为了实现第一个目标（公平共享），调度程序必须在作业数量发生变化时，在作业之间重新分配资源。关键的设计问题是，在提交新作业时，如何处理正在运行作业的任务（构成作业的工作单元），以便为新作业提供资源。在高层次上，可以采取两种方法：

1. **杀死**正在运行的任务为新工作腾出空间。
2. **等待**运行任务完成。

Killing 立即重新分配资源，并为新作业提供对 **locality** 的控制，但它的严重缺点是浪费了被杀任务的工作。另一方面，等待没有这个问题，但==会对公平性产生负面影响==，因为新作业需要等待任务完成才能实现其共享和局部性，并且在释放的节点上，新作业可能没有任何输入数据。

与直觉相反，基于等待的算法可以同时实现高公平性和高数据局部性。首先，在大型集群中，<u>任务的完成率非常高</u>，以至于可以在比作业持续时间**==短得多==**的时间尺度上，将<u>资源重新分配给新作业</u>。然而，严格实现的公平共享会损害局部性，因为根据公平性，下一步要调度的作业在当前空闲节点上可能没有数据。为解决这个问题，通过一种称为**延迟调度**的简单算法稍微放宽下公平性，该算法中的作业等待有限的时间，以便在有数据的节点上获得调度机会。**我们表明，非常少量的等待就足以使局部性接近 100%**。延迟调度在典型的 Hadoop 工作负载中表现良好，因为 Hadoop 任务相对于作业来说**短**，而且有**多个位置**可以运行一个任务来访问每个数据块。

延迟调度适用于公平共享之外。 通常，任何调度策略都定义了为作业分配资源的顺序。延迟调度只是要求我们有时不按顺序，将资源分配给作业以提高数据局部性。我们利用 HFS 中延迟调度的通用性，实现了一种基于Facebook用户需求的分层调度策略：顶层调度器根据<u>**加权公平共享**</u>在用户之间划分 **==<u>slot</u>==**，但用户可以使用 FIFO 或**<u>公平共享</u>**来调度自己的作业。

尽管我们的工作源自 Facebook 的数仓工作负载，但它也适用于其他环境。我们的 Yahoo! 联系人还报告说，工作排队延迟是一个很大的挫折。 我们的工作还与共享学术 Hadoop 集群 [8, 10, 14] 以及 Hadoop 以外的系统相关。 最后，延迟调度的简单性的一个结果是它可以以分布式方式实现； 我们将在第 6 节中讨论这一点的含义。

本文组织如下。 第 2 节提供了 Hadoop 的背景知识。 第 3 节分析了一个简单的公平共享模型，以确定何时公平与局部性发生冲突，并解释了为什么延迟调度可以预期执行良好。 第 4 节描述了 HFS 的设计和我们延迟调度的实现。 我们在第 5 节评估 HFS 和延迟调度。第 6 节讨论延迟调度的限制和扩展。 第7节调查相关工作。 我们在第 8 节总结。

## 2. Background

Hadoop 的 MapReduce 实现类似于 Google [18] 的实现。 Hadoop 运行在称为 HDFS 的分布式文件系统上，和 GFS [21] 类似，该系统存储每个块的三个副本。用户提交由 `map` 函数和 `reduce` 函数组成的 `job`。 Hadoop 将每个作业分解为**任务**。首先，`map` 任务处理每个输入块（通常为 64 MB）产生**中间结果**键值对。每个输入块有一个 `map` 任务。接下来，`reduce` 任务传递每个键的中间值列表，并通过用户的 `reduce` 函数，生成作业的最终输出。

Hadoop 的作业调度由一个 *master* 管理多个 *slaves* 来完成。每个 *slave* 都有固定数量的 *map slot* 和 *reduce slot*，用于运行任务。管理员通常将 slot 数设置为每个核心一个或两个。*slaves* 每隔几秒向 *master* 发送**心跳**，报告空闲的 *map* 和 *reduce* 的 *slot* 数量，*master* 基于此信息分配任务。

Hadoop 默认以 FIFO 顺序调度运行作业，有五个优先级。当调度器收到一个表示 map 或 reduce slot 空闲的心跳时，会按**优先级顺序**和**提交时间**扫描作业，以找到所需类型的任务。对于 `map`，Hadoop 使用 Google 的 MapReduce [18] 中的**局部性优化**：在选择作业后，调度器**贪婪地**在作业中挑选数据最接近 slave 的map任务（首先选择同一节点，然后是同一机架，最后是远程机架）。

## 3. 延迟调度

回想一下，我们的目标是**<u>在统计上多路复用</u>**集群，同时对公平性的影响最小（即快速为新作业公平地分配资源份额），并实现<u>==较好的==</u>数据局部性。 本节，我们分析一个简单的公平共享算法来回答两个问题：

1. 应该如何将资源重新分配给新的作业？
2. 如何实现数据本地化？

为了回答第一个问题，我们考虑两种重新分配资源的方法：**杀死**现有作业中的任务为新作业腾出空间，以及**等待**任务完成以将 slot 分配给新作业。 **等待**的优点是可以瞬间完成，缺点是浪费了被杀掉任务所做的工作。我们发现，当多个用户共享一个集群时，且作业长度超过平均任务长度时，等待对作业响应时间的影响很小。这些条件适用于 Facebook 和 Yahoo! 的工作负载，因此我们将 HFS 建立在等待的基础上。

选择**等待**后，我们将注意力转向了局部性。我们**确定**了严格遵循公平共享时出现的两个局部性问题：<u>==队头调度==</u>和==<u>粘性插槽</u>==。 为保持公平性，这两种情况下，调度程序都被迫从没有本地数据的节点上为作业启动任务。我们提出了一种称为**延迟调度**的算法，它通过要求作业在具有本地数据的节点上等待调度机会来**暂时放宽公平性**以提高局部性。我们分析等待时间如何影响局部性和作业响应时间。

简单起见，我们最初关注一层的局部性：将任务与其输入数据放在同一节点上。 我们在 3.6 节开始考虑机架局部性。

### 3.1 朴素的公平调度算法

在作业之间公平共享集群的一种简单方法是始终为运行任务最少的作业分配空闲 slot。 只要 slot 足够快地空闲，分配结果就会满足**最大最小公平性** [7]。 为了实现局部性，我们可以在这个 head-of-line 作业中贪心地搜索满足本地性的任务，类似 Hadoop 的 FIFO 调度器。 算法伪代码如下所示：

```c
/*--Algorithm 1 Naive Fair Sharing--*/
when a heartbeat is received from node n:
if n has a free slot then
  sort jobs in increasing order of number of running tasks
  for j in jobs do
    if j has unlaunched task t with data on n then
      launch t on n
    else if j has unlaunched task t then
        launch t on n
      end if 
    end for
end if
```

HFS 的第一个版本中实现了这个算法。我们将算法分别应用于 map slot 和 reduce slot。 此外，我们只对 map 任务使用了局部性检查，因为 reduce 任务通常需要从所有节点读取大致相等的数据量。

### 3.2 调度响应性

我们考虑的**第一个问题是提交新作业到集群时如何重新分配任务**。对于公平份额为 *F* 个 slot 的作业 *j*， 理想情况下，我们希望它的调度响应时间与它在有 *F* 个 slot 的私有小集群上单独运行时的响应时间相似。假设 *j* 需要 *J* 秒才能在私有集群上运行。如果将 *j* 提交到使用**等待调度算法**的共享集群，我们计算 *j* 需要多长时间才能接收到它的 slot 份额。如果集群中的所有插槽都已满，则为 *j* 分配 slot 的速率将是任务完成的速率。假设平均任务长度为 *T* ，并且集群包含 *S* 个 slot。 然后平均每 *T/S* 秒就会释放一个 slot，因此 *j* 预计将等待 *FT/S* 秒以获取其所有插槽。 与 *j* 的运行时间相比，这个等待时间可以忽略不计，只要：
$$
J \gg F \frac{T}{S}
$$

> 2. 任务完成的时间分布**大致均匀**也是必要的。这在大型多用户集群中很可能发生，因为任务持续时间可变，作业时间提交也可变。

因此，如果至少满足以下条件之一，**等待**不会显着影响作业响应时间：

1. **多个作业**：当有多个作业运行时，每个作业在集群中所占份额 $f= \frac{F}{S}$ 很小。
2. **小型作业**：具有少量任务的作业（我们称之为**小型作业**）也将具有很小份额的 *$f$* 值。
3. **长时作业**：$J > T$ 产生很少开销的工作。

在来自 Facebook 的工作负载跟踪中，我们发现大多数任务都很短，而且大多数作业都很小，因此即使在集群负载很大时也可以快速重新分配插槽。图 1 显示了 2009 年 10 月一周内 map 任务的耗时、作业耗时和 reduce 任务耗时的 CDF。map 任务耗时的中位数长度为 19 秒，明显小于作业耗时的中位数 84 秒。reduce 耗时更长（中位数为 231s），但发生这种情况是因为大多数作业没有很多 reduce 任务，因此少数有耗时较长 reduce 任务的作业贡献了 CDF 的很大一部分。

> - [ ] 图 1

我们还计算了在特定类型的大多数 slot 已满的高负载期间，释放 slot 的速率。95% 以上的 map slot 在 21% 的时间内被分配，平均而言，在高负载期间，每秒释放 27.1 个 slot（总共 3100 个）。只有 4% 的时间 95% 以上的 reduce slot 被分配，此时，每秒释放 3100 个 slot 中的 **3.0** 个。根据跟踪，这些速率足以让 83% 的作业在 10 秒内启动，因为 83% 的作业少于 271 个 map 任务和 30 个 reduce 任务。

最后，在 Yahoo! 用于数据分析和即时查询的集群（ 3000 个节点）中，我们看到了与 Facebook 相似的**任务和作业时长**：job 中位数时间为 78 秒，map 中位数为 26 秒，reduce 中位数为 76 秒。

### 3.3 朴素公平调度算法的数据局部性问题

MapReduce 使调度复杂化的主要原因是需要将任务放置在其输入数据附近。 **局部性**增加了吞吐量，**因为大型集群中的网络带宽远低于集群磁盘的总带宽 [18]**。在包含数据的节点 (*node locality*) 上运行最有效，但是当这不可能时，则在同一机架上运行 (*rack locality*) 比在**机架外**运行要快。现在，我们只考虑节点局部性。我们描述了由天真的公平共享引起的两个局部性问题：<u>==队头调度==</u>和==<u>粘性插槽</u>==。

#### 3.3.1 队头调度

**第一个局部性问题**出现在小作业中（具有小输入文件的作业，因此要读取少量数据块）。这里的问题是，每当一个作业到达算法 1 中**排序列表**的头部时（==即运行任务最少==），它的一个任务就会在下一个空闲 slot (无论 slot 在哪个节点）上启动。如果这个作业很小，则不太可能在提供给它的节点上有数据。例如，在 10% 节点上有数据的作业，只会实现 10% 的局部性。


我们在 Facebook 一个没有延迟调度的 HFS 版本中观察到了这个队列调度问题。图 2 显示了 2009 年 3 月在 Facebook 上运行的不同 map 数量作业的局部性（回想一下，每个输入块有一个 map 任务）。<u>每个点代表一组作业大小</u>。第一个点表示有 1 到 25 个 map 的作业，仅实现 5% 的节点局部性和 59% 的机架局部性。不幸的是，这种行为是有问题的，因为 Facebook 大多数 job 都很小。事实上，Facebook 58% 的工作都属于第一组（1-25 个 map）。小型作业如此普遍，因为即席查询和定期报告作业都适用于小型数据集。

#### 3.3.2 粘性插槽

如果使用公平共享，**<u>第二个局部性问题</u>粘性插槽**也会出现在大型作业中。这里的问题是，有一种重复分配 job 到同一个 slo t的趋势。例如，假设在一个 100 节点的集群中有 10 个作业，每个节点有一个 slot，每个作业有 10 个正在运行的任务。假设作业 *j* 在节点 *n* 上完成了一项任务。节点 *n* 现在请求一个新任务。 此时，*j* 有 9 个正在运行的任务，而所有其他作业都有 10 个。因此，算法 1 再次将节点 *n* 上的插槽分配给作业 *j*。因此，在稳定状态下，**作业永远不会离开其原始位置**。 这会导致数据局部性不佳，因为输入文件在集群中是条带化的，因此每个作业都需要在每台机器上运行一些任务。

**粘性插槽**的影响取决于作业数量、每个节点的 slot 数量（表示为 *L*），文件系统中每个块的副本数（表示为 *R*）。假设作业 *j* 在集群中的**<u>份额比</u>**是 *f* 。然后对于任何给定的块 *b*，<u>没有运行 *j* 任务的 slot 位于**块 b** 副本的节点上的概率为 $(1 - f )^{RL}$</u>：*b* 有 *R* 个副本，每个副本都在一个有 *L* 个 slot 的节点上，slot 不属于 *j* 的概率是$1-f$。 因此，*j*  预计最多达到 $1 - (1 - f )^{RL}$ 局部性。 我们在图 3 中针对不同的 *R* 和 *L* 以及不同数量的并发作业（具有相同的集群份额）绘制了局部性界限。即使有较大的 *R* 和 *L*，对于 15 个作业，局部性也低于 80% ；30 个作业，低于 50%。

有趣的是 Hadoop 中不会出现**粘性插槽**，因为 Hadoop 计算正在运行任务的方法有 bug。Hadoop 任务在完成工作后进入**提交挂起**状态，这时会请求权限，将其**输出**重命名为**最终文件名**。master <u>将处于此状态的 job 任务</u>**统计为正在运行**；而 slave 则不是；因此，可以为另一个作业的任务分配 slot。虽然这不正确（破坏公平性），但它对吞吐量和响应时间的影响有限。尽管如此，我们还是解释了**粘性插槽**以向其他系统设计者警示这个问题。例如，Dryad [24] 中已经报道了**粘性插槽**。在第 5 节中，我们展示了在没有此错误的 Hadoop 版本中，==粘性插槽将吞吐量降低了 2 倍==。

### 3.4 延迟调度

之所以会发生这两个问题，是因为严格遵循排队顺序会强制调度<u>**没有本地数据**</u>的作业。我们通过一种简单技术，称为延迟调度来解决它们。当一个节点请求任务时，如果队头的 job 无法启动一个本地任务，就跳过它，并查看后续的jobs。但是，如果作业跳过的时间足够长，我们就开始允许它启动非本地任务，以避免饥饿。**延迟调度**背后的关键见解是，分配给作业的**第一个 slot**，虽然不太可能有数据，但任务完成得如此之快，以至于**一些有该 job 数据 slot** 将在接下来的几秒内被释放出来。

这一节我们考虑延迟调度的简单版本，在这里我们允许跳过作业 *D* 次。算法伪代码如下所示：

```basic
/** Algorithm 2 Fair Sharing with Simple Delay Scheduling **/
Initialize j.skipcount to 0 for all jobs j
when a heartbeat is received from node n:
if n has a free slot then
  sort jobs in increasing order of number of running tasks
  for j in jobs do 
    if j has unlaunched task t with data on n then
      launch t on n
      set j.skipcount = 0
    else if j has unlaunched task t then
          if j.skipcount >= D then
            launch t on n
      else
            set j.skipcount = j.skipcount + 1
      end if
    end if
  end for
end if
```

请注意，一旦作业被跳过 *D* 次，我们就让它启动任意多个非本地任务，并不重置其 `skipcount`。 但是，如果它再次设法启动本地任务，我们将其 `skipcount` 设置回 0。我们在延迟调度分析中解释了这种设计的基本原理。

### 3.5 分析

在本节中，我们将探讨算法 2 中的最大跳过计数 *D* 如何影响**局部性**和响应时间，以及如何设置 *D* 以实现不同级别的**局部性**。 我们发现：

1. 非局部性随 *D* 呈指数递减。
2. 达到给定级别局部性所需的**等待**是平均任务长度的一小部分，并且随着每个节点的 slot 数 *L* 线性减少。

假设有一个 *M* 节点的集群，每个节点有 *L* 个 slot，总共 *S* = *ML* 个 slot。此外，每次让 *P~j~* 表示作业 *j* 上还有待处理数据的节点集，我们将其称为作业 *j* 的**首选**节点，并让 $p_j = \frac {|P_j|}M$ 是 *j* **首选**节点的比例。 为了简化分析，我们假设所有任务具有相同的长度 T，并且与节点集 P~j~ 不相关（例如，每个作业都有一个大输入文件，因此每个节点都有数据，或者每个作业都有不同的输入文件）。

我们首先考虑 *D* **对局部性的改善有多大**。假设作业 *j* 远低于其公平份额。那么 *j* 在每个空闲 slot 上有数据的概率 *p~j~* 。如果 *j* 在启动非本地任务之前最多等待 *D* 个槽，那么它**没有**数据局部性任务的概率为 $(1 − p_j)^D$。 随 *D* 呈指数下降。 例如，数据位于10%节点（*p~j~*=0*.*1）上的作业，有 65% 的概率以 *D* = 10 启动本地任务，在 *D*=40 时，有99% 的概率启动本地任务。

第二个问题是在不满足作业的公平份额时，**作业要等待多长时间**才能启动本地任务。由于集群中有 *S* 个 slot，因此平均每 $ \frac T S$ 秒就释放一个 slot。因此，一旦作业 *j* 到达队列头部，最多等待 $D \frac S T$ 秒，就可以启动**非本地**任务（前提是它停留在队列的头部^3^）。如果 *S* 很大，则此等待将远小于平均任务长度。特别是，等待本地任务可能比运行非本地任务花费更少的时间：在我们的实验中，本地任务的运行速度比非本地任务快 2 倍。另请注意，如果节点数量固定，则等待时间随每个节点 slot 数量线性减少。

> 3. 作业一旦到达队列头部，很可能会留在那里，因为队列头部的作业是**运行任务数量最少**的作业。作业因低于其份额而丢失的 slot 必须已分配给其他作业，因此其他作业可能高于其公平份额。

最后，我们对**如何设置 D** 以达到所需的**局部性级别**^4^ 进行近似分析。假设我们希望在有 *M* 个节点、每个节点 *L* 个 slot 和复制因子 *R* 的集群上，对于有 *N* 个任务的作业，实现大于 λ 的局部性。我们计算有 *N* 个任务的作业 *j*，在其生命周期内的**局部性预期**，方法是计算该作业在有 *N*, *N − 1*, . . . ，1 个任务时，启动本地任务概率的平均值。当 j 还有 K 个任务要启动时，$p_j = 1−(1− \frac KM)^R$，因为给定节点**没有** j 的输入块副本的概率是 $(1 - \frac KM)^R$。因此，此时 j 启动本地任务的概率为 $1-(1-p_j)^D = 1-(1- \frac KM)^{RD} \ge 1-e^{−RDK/M} $。在 K = 1 到 N 之间取该量的平均值，给定跳过计数 D，作业 j 的局部性预期至少是：

> 4. 此分析没考虑作业可以在启动第一个任务后，**无需等待即可启动非本地任务**。但是，这只发生在工作结束时，因此在大型作业中无关紧要。 另一方面，我们使用的不等式低估了给定 *D* 的局部性。
>
> - [ ] 推导公式

求解$l(D) \ge \lambda$，我们发现需要设置：
$$
D \ge - \frac M R ln\lgroup \frac{(1-\lambda)N}{1+1-\lambda)N} \rgroup
$$
例如，对于 λ = 0*.*95、*N* = 20 和 *R* = 3，我们需要 $D \ge 0.23M$。 此外，作业等待本地任务的最长时间为 $\frac D S T = \frac D {LM} T = \frac {0.23} L T$。 例如，如果每个节点有 *L* = 8 个插槽，则此**==等待==**是平均任务长度的 2.8%。

#### 3.5.1 Long Tasks and Hotspots

前面**假设**所有**作业的任务长度相同**，并且 job 的首选位置集 *P~j~* 不相<u>关</u>。 有两个因素可以打破这些假设：

1. 有些作业可能有很长的任务。 如果一个节点所有的 slot 都在运行任务，那么该节点可能无法快速释放出足够的空间，以便其他作业实现局部性。

2. 大量作业可能对某些节点感兴趣。我们称这些节点为**热点**。 例如，多个作业可能试图读取同一个小文件。

我们注意到，热点和运行长任务的节点都是相对持久的条件。 这就是为什么在算法 2 中，如果作业已被跳过 *D* 次，我们允许作业启动任意多个非本地任务，直到它们再次启动本地任务。如果 *D* 设置得足够高，当没有热点或长任务“阻塞”节点时，作业有很好的机会在其首选节点上启动本地任务，那么一旦作业被跳过 *D* 次，作业的首选节点很可能确实被阻塞了，所以我们不应该继续等待。

长任务和热点对局部性的影响程度取决于工作负载、文件复制数 *R* 和节点 slot 数 *L*。一般来说，除非长任务和热点很常见，否则对局部性影响不大。例如，如果运行长任务的 slot 的比例是 ϕ，那么所有具有给定块副本的节点都运行长任务的概率是 ϕ*RL*。 在 *R* = 3 和 *L* = 6 的集群上，只要 ϕ *<* 0*.*8，该值就小于 2%。我们在实践中没有看到长任务和热点的重大问题。尽管如此，对于这些情况很常见的集群，我们提出了两种解决方案：

**长任务平衡**：为了降低节点被长任务<u>**填满**</u>的几率，我们可以通过改变算法 2 中的局部性检查来将长任务分散到整个集群，对于那些<u>正在运行的长任务</u>数量高于平均水平的节点，不在其上启动长任务作业。虽然我们事先不知道哪些作业有长任务，但我们可以将新作业视为长任务作业，如果它们的任务完成得很快，则将它们标记为短任务作业^5^。

> 5. 作业中的任务因为运行相同的功能，所以长度相似。

**热点复制**：因为像 HDFS 这样的分布式文件系统随机在节点上放置块，只有在多个作业需要读取同一个数据文件，如果文件足够小，副本只出现在一小部分节点上，才可能发生**热点**。这种情况下，没有一种调度算法能够在没有过多排队延迟的情况下获得较高的局部性。相反，动态提高热点小文件的副本数会更好。

### 3.6 机架局部性

大型集群中的网络通常以多级层次结构组织，节点在最低层，20-80 个节点组成一个机架，一层或多层的聚合交换机连接机架 [24]。通常，机架内每个节点的带宽远高于机架间每个节点的带宽。因此，当无法调度任务到包含其数据的节点上时，最好调度任务到包含其数据的机架上。

可以扩展算法 2，通过给每个作业**两个等待期**来实现多级调度。首先，如果头部作业最多被跳过 *D*1 次，则只允许启动 node-local 任务。一旦作业被跳过 *D*1 次，则进入延迟调度的第二级，在那里它只允许启动 rack-local 任务。 如果作业在此级跳过 *D*2 次，则允许启动非本地任务。我们分析的一个很好的结果是，*D*2 可以比 *D*1 小得多：因为机架比节点少得多，很快就能在机架中找到包含其数据的 slot，所以作业不会被跳过很多次。

我们已经在 HFS 中实现了这个算法，并在第 4.1 节中详细描述了它。 类似的算法可用于具有 2 个以上层次结构的网络。

## 4. Hadoop 的公平调度器的设计

第 3 节中描述的简单公平调度程序为每个作业分配了相同的集群份额，对于用户数量较少的集群来说已经足够了。 但是，为了满足 Facebook 等大型组织的需求，我们希望解决此模型的几个缺点：

1. 一些用户可能比其他用户运行更多的作业；我们希望在用户层面公平分享，而不是作业。
2. 用户希望自己控制作业的调度。例如，提交多个批处理作业的用户可能希望它们按 FIFO 顺序运行，以便按顺序获得结果。
3. 即使集群有许多长用户任务的负载，**生产作业也要以可预测的方式执行**。

我们设计的 Hadoop 公平调度器 (HFS) 解决了这些问题。HFS 使用两级调度层次结构。在顶层，HFS 使用加权公平共享跨**池**分配任务 slots。 每个用户有一个**池**，但也可以为特定工作负载（例如生产作业）创建特殊的**池**。在第二层，使用有优先级的 FIFO 或第二层公平共享，在**池**中的作业之间分配 slot。图 4 显示了一个示例的**池**层次结构。 HFS 可以很容易地推广到支持**多级池层次结构**，或者支持除 FIFO 和池内公平共享以外的策略。

除了标准的加权公平共享调度算法外，我们还提供了一项功能来支持生产作业。每个池都可以被赋予一个**最小份额**，表示只要**池**中有作业，就可以保证为其提供的最小 slot 数，即使池的公平份额小于这个数量（例如，因为大量用户正在运行作业）。HFS 总是优先满足最低份额而不是公平份额，并且可能会杀死任务以满足最低份额。管理员应根据作业满足特定 SLO 所需的 slot 数（例如，每 15 分钟导入一次日志，或每小时删除一次垃圾邮件），为生产作业设置最小份额。如果所有池的最小份额总和超过集群中的 slot 数，HFS 会记录警告并平均缩减最小份额，直到它们的总和小于 slot 总数。

最后，虽然 HFS 大部分时间使用**等待**重新分配资源，但它也支持**杀死任务**。这是为了防止**错误作业的长时任务**或**贪婪的用户**占用大量的集群份额。HFS 有两个终止任务的超时设置。首先，每个池都有一个**最小共享超时**，*T~min~*。 如果在提交作业后的 *T~min~* 秒内，池没有收到其最小份额，我们将终止任务以满足池的份额。其次，有一个全局**公平共享超时**，*T~fair~*，用于在**池**<u>缺乏公平共享时</u>终止任务。我们希望管理员根据其 SLO 为每个生产池设置 *T~min~*，并根据用户可以容忍的延迟级别为 *T~fair~* 设置更大的值。在选择要终止的任务时，我们会<u>在池中选择最近启动的高于公平份额的</u>任务，最大限度地减少浪费的工作。

### 4.1 HFS 中的任务分配

HFS 为空闲 slot 分配任务分为两个步骤：**首先**，我们根据分层调度策略创建一个排序的作业列表。**其次**，我们向下扫描此列表以查找要从中启动任务的作业，应用**延迟调度**来跳过在有限时间内在分配的节点上没有数据的作业。相同的算法独立应用于 map slot 和 reduce slot，reduce不使用延迟调度，因为它们通常需要从所有节点读取数据。

为了创建作业的排序列表，我们使用递归算法。**首先**，我们对**池**进行排序，将低于其最小份额的池放在列表最前面（<u>==根据每个池低于其最小份额的程度来打破关系==</u>），并按 $\frac{current share}{weight}$ 对其他**池**进行排序，以实现加权公平共享。 **然后**，我们根据**池**的内部策略（FIFO 或公平共享）对**池**内作业进行排序。

考虑到一些实际因素，我们的延迟调度实现与 3.4 节中的简化算法略有不同。首先，我们没有使用最大跳过计数 *D* 来确定作业等待本地任务的时间，而是以秒为单位设置**最大等待时间**。 当集群中的大量 slot 被长时任务填满，并且以缓慢的速度释放时，这**允许作业在可预测的时间内启动**。 其次，无法为作业启动 node-local 任务时实现 rack locality，使用**两层延迟调度** —— 作业等待 *W*1 秒找到一个 node-local 任务，然后 *W*2 秒找到 rack-local 任务。算法如下所示：

> - [ ] 算法 3

作业从 locality 级别 0 开始，此时只能启动节点本地任务。如果等待了至少 *W*1 秒，进入 locality 级别 1，此时可启动 rack-local 任务。如果再等 *W*2 秒，则进入第 2 级，可启动 off-rack 任务。最后，如果一个作业启动了一个比它所在级别“更本地”的任务，它会回到之前的级别，如第 3.5.1 节所述。 对于具有多于两级网络层次结构的集群，该算法很容易推广到更多的局部级别。

我们希望管理员用 3.5 节中的分析，根据集群中 slot 的释放率和所需的本地级别来设置等待时间 *W*1 和 *W*2。 例如，在 Facebook，当集群处于负载状态时，我们看到每秒释放 27 个 map slot，文件复制数 *R* = 3 ，并且有 *M* = 620 台机器。因此，在允许启动非本地任务之前，设置 *W*1 = 10s 将为每个作业提供大约 *D* = 270 个调度机会。这足以让 *K* = 1 个任务的作业至少达到 $1 - e^{\frac{-RDK}M}= 1 - e^{\frac{-3*270*1}{620}} = 73\% $ 的局部性，并让具有 10 个任务的作业达到 90% 的局部性。

## 5. 评估

We have evaluated delay scheduling and HFS through a set of macrobenchmarks based on the Facebook workload, microbenchmarks designed to test hierarchical scheduling and stress delay scheduling, a sensitivity analysis, and an experiment measuring scheduler overhead.

We ran experiments in two environments: Amazon’s Elastic Compute Cloud (EC2) [1] and a 100-node private cluster. On EC2, we used “extra-large” VMs, which appear to occupy a whole physical nodes. Both environments are atypical of large MapReduce installations because they have fairly high bisection bandwidth; the private cluster spanned only 4 racks, and while topology information is not provided by EC2, tests revealed that nodes were able to send 1 Gbps to each other. Therefore, our experiments understate potential performance gains from locality. We ran a modified version of Hadoop 0.20, configured with a block size of 128 MB because this improved performance (Facebook uses this set- ting in production). We set the number of task slots per node in each cluster based on hardware capabilities. Table 1 lists the hardware and slot counts in each environment.

## 6. 讨论

我们的工作本质上是利用率和公平性之间的经典权衡。配置集群计算基础设施时，每个用户一个集群（很公平但利用率很低）和所有用户使用单一的 FIFO 集群（利用率很高但没有公平性）之间存在一定的差别。我们的工作在这个范围内实现了一个最佳点 —— 有效地复用集群，同时通过公平共享为每个用户提供与私有集群相当的响应时间。

为了实现公平共享，我们必须考虑利用率和公平性之间的另外两个权衡：第一，在提交新作业时是杀死任务还是等待任务完成，第二，如何实现数据本地化。我们提出了一种称为延迟调度的简单策略，它通过等待任务完成来实现公平性和局部性。==集群环境的两个关键方面使延迟调度能够很好地执行==：首先，与作业相比，**大多数任务都很短**；其次，任务可以在**多个位置运行**以读取给定的数据块，因为像 Hadoop 这样的系统支持每个节点多个 slot。

延迟调度在满足这两个条件的环境中表现良好，包括 Yahoo! 和 Facebook 的 Hadoop 环境。如果大部分任务比平均作业长得多，或者每个节点的 slot 很少，则延迟调度将**无效**。但是，随着集群技术的发展，我们相信这两个因素都会有所改善。首先，缩短任务可以提高容错能力 [18]，因此随着集群的增长，我们希望更多的开发人员将他们的工作拆分为短任务。其次，由于多核，集群节点变得“更大”，因此可以同时支持更多任务。本着同样的精神，企业正在为每个节点放置更多磁盘——例如，谷歌在其 petabyte 排序基准测试中。每个节点使用了 12 个磁盘 [9]。最后，10 Gbps 以太网将大大增加机架内的网络带宽，这使得 rack-local 任务和 node -local 任务的性能一样好。<u>这将使任务能够有效访问其输入块的位置数量增加一个数量级</u>。

由于延迟调度只涉及按顺序跳过作业（这个顺序是指“接下来应该安排谁”），我们相信它可以在 Hadoop 和 HFS 之外的各种环境中使用。现在讨论几种可以推广延迟调度的方法。

**公平共享以外的调度策略：**延迟调度可应用于任何产生排序作业列表的排队策略。例如，我们在第 5.2.2 节中展示了它还可以在 FIFO 下使吞吐量翻倍。

**数据本地性以外的调度首选项：**某些作业可能更喜欢在**相同**位置运行多个任务，而非在其输入块附近运行每个任务。例如，一些 Hadoop 作业有一个由所有任务共享的大数据文件，并使用称为分布式缓存的功能动态复制到运行作业任务的节点上[4，12]。在这种情况下，我们的算法中的局部性检查可以改为首选在有缓存文件的节点上运行任务。为了使集群能够在<u>**想要重用其 slot 的作业**</u>和**<u>想要读取分布在集群中的数据的作业</u>**之间共享，<u>我们可以使用第 3.5.1 节中针对长任务提出的负载平衡机制，将来自前者的任务分布在整个集群中</u>。

**Slots 以外的负载管理机制：** 集群中的任务可能具有异构资源需求。为了提高利用率，节点上支持的任务数量可以根据其负载动态变化，而不是像在 Hadoop 中那样固定。 只要每个作业在每个节点上被调度的机会大致相等，延迟调度就能实现数据局部性。

**分布式调度决策：** 我们还在 Nexus [22] 中实现了延迟调度，这是一个两级集群调度器，允许 Hadoop 或其他集群计算框架的多个实例在共享集群上共存。在 Nexus 中，来自每个框架的主进程向 Nexus 主进程注册，以接收集群上的 slot。Nexus master 通过向适当的框架提供“slot offer”（使用公平共享）来调度 slot，但是允许框架拒绝 offer 以等待具有更好数据位置的 slot。当在延迟调度的 Nexus 上运行多个 Hadoop 实例时，我们已经看到了类似于第 5 节中的局部性改进。以分布式方式实现较好的数据局部性这一事实，提供了显著的实际好处：首先，可以运行 Hadoop 的多个隔离实例，以确保实验作业不会使运行生产作业的实例崩溃；第二，多个版本的 Hadoop 可以共存；最后，企业可以使用多个集群计算框架，并为每个应用程序选择最好的一个。

## 7. 相关工作

**Scheduling for Data-Intensive Cluster Applications:** The closest work we know of to our own is Quincy [24], a fair scheduler for Dryad. Quincy also tackles the conflict between locality and fairness in scheduling, but uses a very different mechanism from HFS. Each time a scheduling decision needs to be made, Quincy represents the scheduling problem as an optimization problem, in which tasks must be matched to nodes and different assignments have different costs based on locality and fairness. Min-cost flow is used to solve this problem. Quincy then kills some of the running tasks and launches new tasks to place the cluster in the configuration returned by the flow solver.

**数据密集型集群应用程序的调度：** 我们所知道的最接近我们自己的工作是 Quincy [24]，它是一种公平的 Dryad 调度程序。Quincy 还在调度中解决了局部性和公平性之间的冲突，但使用了与 HFS 非常不同的机制。每次需要做出调度决策时，Quincy 将调度问题表示为优化问题，其中任务必须与节点匹配，不同的分配基于局部性和公平性具有不同的成本。最小成本流就是用来解决这个问题的。 Quincy 然后终止一些正在运行的任务并启动新任务以将集群置于流求解器返回的配置中。

While killing tasks may be the most effective way to reassign resources in some situations, it wastes computation. Our work shows that waiting for suitable slots to free up can also be effective in a diverse real-world workload. One of the main differences between our environment and Quincy’s is that Hadoop has multiple task slots per node, while the system in [24] only ran one task per node. The probability that all slots with local copies of a data block are filled by long tasks (necessitating killing) decreases exponentially with the number of slots per node, as shown in Section 3.5.1. Another important difference is that task lengths are much shorter than job lengths in typical Hadoop workloads.

At first sight, it may appear that Quincy uses more information about the cluster than HFS, and hence should make better scheduling decisions. However, HFS also uses information that is *not* used by Quincy: delay scheduling is based on knowledge about the *rate* at which slots free up. Instead of making scheduling decisions based on point snapshots of the state of the cluster, we take into account the fact that many tasks will finish in the near future.

Finally, delay scheduling is simpler than the optimization approach in Quincy, which makes it easy to use with scheduling policies other than fair sharing, as we do in HFS.

**高性能计算 (HPC)：** HPC 集群的批量调度程序，如 Torque [13]，支持作业优先级和资源消耗感知调度。 但是，HPC 作业在固定数量的机器上运行，因此不可能像我们在 Hadoop 中那样随时间改变作业的分配以实现公平共享。 HPC 作业通常也受 CPU 或通信限制，因此对数据局部性的需求较少。

**Grids:** Grid schedulers like Condor [28] support locality constraints, but usually at the level of geographic sites, because the jobs are more compute-intensive than MapReduce. Recent work also proposes replicating data across sites on demand [17]. Similarly, in BAD-FS [16], a workload scheduler manages distribution of data across a wide-area network to dedicated storage servers in each cluster. Our work instead focuses on task placement in a local-area cluster where data is stored on the same nodes that run jobs.

**网格：** 像 Condor [28] 这样的网格调度器支持局部性约束，但通常是在地理站点级别，因为这些作业比 MapReduce 更需要计算密集型。 最近的工作还建议按需跨站点复制数据 [17]。 类似地，在 BAD-FS [16] 中，工作负载调度程序管理跨广域网到每个集群中专用存储服务器的数据分布。 相反，我们的工作侧重于将任务放置在本地集群中，其中数据存储在运行作业的相同节点上。

**并行数据库：** 与 MapReduce 一样，并行数据库在集群上运行数据密集型工作负载。然而，数据库查询通常作为长时运行的进程，而不是像 Hadoop 那样的短任务，减少了细粒度共享的机会。 就像在 HPC 调度程序中一样，查询必须在队列中等待才能运行 [6]，并且单个“怪物查询”可以占用整个系统 [11]。可保留一些资源，用于在运行批处理查询时仍可执行交互式查询 [6]，但没交互式查询时，会导致资源没充分利用。相反，我们 Hadoop 的调度程序可将所有资源分配给批处理作业，并在启动交互式作业时快速重新分配 slot。

**公平共享：**在网络和操作系统领域开发了大量**公平共享**算法 [7, 19, 25, 30]。这些调度程序许多已经扩展为分层设置 [15, 20, 27, 29]。 这些算法复杂且可扩展，但因为它们只共享一种资源，所以不处理数据局部性。

## 8. 结论

随着像 MapReduce 和 Dryad 这样的数据密集型集群计算系统越来越流行，用户之间共享集群的需求越来越强烈。 为了有效地复用集群，调度器必须同时考虑公平性和数据局部性。 我们已经证明，严格执行公平会导致局部性的丧失。 但是，使用称为延迟调度的简单算法，通过稍微放宽公平性，可以实现接近 100% 的局部性。 我们已经在 HFS 中实现了延迟调度，它是一个公平的 Hadoop 调度程序，并表明它可以在多用户工作负载中将小作业的响应时间提高 5 倍，并且可以在 IO 繁重的工作负载中将吞吐量提高一倍。 HFS 是开源的并包含在 Hadoop 中：一个没有延迟调度的旧版本在 Hadoop 0.20 中，具有本文所述所有功能的版本将出现在 Hadoop 0.21 中。
